{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>XSpecT is an analysis software package designed for ultrafast x-ray free electron laser experiments. It is written in python following the principles of object-oriented programming.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>The source code is available for download from the XSpecT github repo.</p>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>Check out our quick start examples for XAS and XES, as well as the example jupyter noteboks found here.</p>"},{"location":"index.html#license","title":"License","text":"<p>Copyright 2025 XSpecT Team</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"Getting_started_XAS.html","title":"XAS","text":""},{"location":"Getting_started_XAS.html#importing-dependencies","title":"Importing Dependencies","text":"<p>XSpecT relies on a number of common python packages including:  </p> <ul> <li>h5py for reading HDF5 files</li> <li>NumPy and scipy for data analysis</li> <li>Matplotlib for visualization</li> <li>Other system related packages</li> </ul> <p>Depending on your system you may need to install the necessary dependencies. S3DF users should have the necessary packages by default.</p> <pre><code>import h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import rotate\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import curve_fit,minimize\nimport multiprocessing\nimport os\nfrom functools import partial\nimport time\nimport sys\nimport argparse\nfrom datetime import datetime\nimport tempfile\n</code></pre>"},{"location":"Getting_started_XAS.html#importing-xspect-modules","title":"Importing XSPecT Modules","text":"<p>XSpecT has several main modules for function to control various aspects of the analysis, visualization, diagnostics and overall processing.</p> <pre><code>sys.path.insert(0, './XSpecT/')\nimport XSpect.XSpect_Analysis\nimport XSpect.XSpect_Controller\nimport XSpect.XSpect_Visualization\nimport XSpect.XSpect_PostProcessing\nimport XSpect.XSpect_Diagnostics\n</code></pre>"},{"location":"Getting_started_XAS.html#xas-analysis-example","title":"XAS Analysis Example","text":""},{"location":"Getting_started_XAS.html#setting-up-experiment-parameters","title":"Setting up experiment parameters","text":"<p>Initializing the <code>spectroscopy_experiment</code> class and setting the relevant experiment information<code>lslc_run</code>, <code>hutch</code>, and <code>experiment_id</code> parameters.</p> <pre><code>xas_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(lcls_run=22, hutch='xcs', experiment_id='xcsl1030422')\n</code></pre> <p>These values will be used to obtain the directory for the data which is stored in <code>experiment_directory</code>:</p> <pre><code>xas_experiment.experiment_directory\n</code></pre> <pre><code>'/sdf/data/lcls/ds/xcs/xcsl1030422/hdf5/smalldata'\n</code></pre>"},{"location":"Getting_started_XAS.html#xasbatchanalysis-class","title":"XASBatchAnalysis Class","text":"<p>Instantiating the <code>XASBatchAnalysis</code> class which allows you to set attributes relevant to the analysis such as the HDF5 group keys for the various datasets, filter thresholds, and timing/energy parameters. The class also contain an analysis pipeline method, which controls the sequence of analysis operations.</p> <pre><code>xas=XSpect.XSpect_Controller.XASBatchAnalysis()\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-keys-and-aliases","title":"Setting keys and aliases","text":"<p>The keys, which specify the data to read from the HDF5 file, are defined as a list of strings. For pump-probe XAS measurements this typically includes: </p> <ul> <li>The monochromator energy and set values (epics/ccm_E, epicsUser/ccm_E_setpoint)</li> <li>TT correction values and amplitude (tt/ttCorr, tt/AMPL)</li> <li>Timing stage values (epics/lxt_ttc)</li> <li>Emission CCD detecotr ROI sum values (epix_2/ROI_0_sum)</li> <li>Normalization channel (ipm4/sum).</li> </ul> <p>Their \"friendly\" names serve as an easier to remember alias for the keys and are also defined as a list of strings with the same ordering as the keys. These lists are passed to <code>set_key_aliases</code> which creates the key aliases.</p> <pre><code>keys=['epics/ccm_E', 'epicsUser/ccm_E_setpoint', 'tt/ttCorr', 'epics/lxt_ttc', 'enc/lasDelay', 'ipm4/sum', 'tt/AMPL', 'epix_2/ROI_0_sum'] \nnames=['ccm', 'ccm_E_setpoint', 'time_tool_correction', 'lxt_ttc', 'encoder', 'ipm', 'time_tool_ampl', 'epix']\nxas.set_key_aliases(keys,names)\n</code></pre>"},{"location":"Getting_started_XAS.html#adding-filters","title":"Adding filters","text":"<p>Filters are set using <code>add_filter</code> which takes requires the parameters \\'shot_type\\' (e.g. xray, simultaneous), \\'filter_key\\' (i.e. which dataset to apply the filter to), and the filter threshold.</p> <pre><code>xas.add_filter('xray','ipm',500.0)\nxas.add_filter('simultaneous','ipm',500.0)\nxas.add_filter('simultaneous','time_tool_ampl',0.01)\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-runs","title":"Setting runs","text":"<p>Multiple runs (files) can be analyzed and combined into a single data set using the <code>run_parser</code> method.  Specify the runs as a list of strings or as a single string with space separated run numbers.  Ranges can be specified using numbers separated by a \"-\".</p> <pre><code>xas.run_parser(['240-243 245-254'])\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-timing-parameters","title":"Setting timing parameters","text":"<p>Delay timing range and number of points is set in picoseconds.</p> <pre><code>xas.mintime = -0.5\nxas.maxtime = 2.0\nxas.numpoints = 25\n</code></pre>"},{"location":"Getting_started_XAS.html#normalization-option","title":"Normalization option","text":"<p>Normalization is set by default (False) to use an IPM sum dataset. Alternatively, the scattering liquid ring signal can be used:</p> <pre><code>xas.scattering = True\n</code></pre>"},{"location":"Getting_started_XAS.html#running-analysis-loop","title":"Running Analysis Loop","text":"<p>With the necessary parameters set the analysis procedure can be initiatilized. Here you pass the experiment attributes from <code>xas_experiment</code>. For details of the step by step analysis processes set <code>verbose= True</code> (False is the default).</p> <pre><code>xas.primary_analysis_loop(xas_experiment, verbose=True)\n</code></pre> <pre><code>Obtained shot properties\nHDF5 import of keys completed. Time: 0.02 seconds\nMask: xray has been filtered on ipm by minimum threshold: 500.000\nShots removed: 2645\nMask: simultaneous has been filtered on ipm by minimum threshold: 500.000\nShots removed: 1904\nMask: simultaneous has been filtered on time_tool_ampl by minimum threshold: 0.010\nShots removed: 100\nShots combined for detector epix on filters: simultaneous and laser into epix_simultaneous_laser\nShots (12182) separated for detector epix on filters: xray and laser into epix_xray_laser\nShots combined for detector ipm on filters: simultaneous and laser into ipm_simultaneous_laser\nShots (12182) separated for detector ipm on filters: xray and laser into ipm_xray_laser\nShots combined for detector ccm on filters: simultaneous and laser into ccm_simultaneous_laser\nShots (12182) separated for detector ccm on filters: xray and laser into ccm_xray_laser\nGenerated timing bins from -0.500000 to 2.000000 in 25 steps.\nGenerated ccm bins from 7.105000 to 7.156500 in 54 steps.\nShots combined for detector timing_bin_indices on filters: simultaneous and laser into timing_bin_indices_simultaneous_laser\nShots (12182) separated for detector timing_bin_indices on filters: xray and laser into timing_bin_indices_xray_laser\nShots combined for detector ccm_bin_indices on filters: simultaneous and laser into ccm_bin_indices_simultaneous_laser\nShots (12182) separated for detector ccm_bin_indices on filters: xray and laser into ccm_bin_indices_xray_laser\nDetector epix_simultaneous_laser binned in time into key: epix_simultaneous_laser_time_energy_binned\nDetector epix_xray_not_laser binned in time into key: epix_xray_not_laser_time_energy_binned\nDetector ipm_simultaneous_laser binned in time into key: ipm_simultaneous_laser_time_energy_binned\nDetector ipm_xray_not_laser binned in time into key: ipm_xray_not_laser_time_energy_binned\nObtained shot properties\nHDF5 import of keys completed. Time: 0.03 seconds\n...\n</code></pre>"},{"location":"Getting_started_XAS.html#exploring-analyzed-runs","title":"Exploring Analyzed Runs","text":"<p>The data for each run is stored in <code>analyzed_runs</code> list.</p> <pre><code>xas.analyzed_runs\n</code></pre> <pre><code>[&lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2ea00&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6de1d00&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe71fe580&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fab670&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe75ac550&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe75c4280&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fc07f0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b1f0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b460&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fb5e80&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fb53d0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b9d0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6b00c10&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe72de340&gt;]\n</code></pre> <p>We can check the data shape for the laser-off shots first analyzed run, which has the dimensions of 25 time bins by 54 energy bins.</p> <pre><code>print(\"Data shape:\", xas.analyzed_runs[0].epix_xray_not_laser_time_energy_binned.shape)\n</code></pre> <pre><code>Data shape: (25, 54)\n</code></pre> <p>Since the laser the laser is off, we can average across all time bins for the epix and normalization channels.</p> <pre><code>y = np.average(xas.analyzed_runs[0].epix_xray_not_laser_time_energy_binned, axis = 0)\nnorm = np.average(xas.analyzed_runs[0].ipm_xray_not_laser_time_energy_binned, axis =0)\n</code></pre>"},{"location":"Getting_started_XAS.html#plotting-laser-off-spectrum","title":"Plotting Laser-off Spectrum","text":"<p>Then the laser off spectrum can be plotted versus the monochromator energies.</p> <pre><code>plt.plot(xas.analyzed_runs[0].ccm_energies, y/norm, label=\"Laser-off\")\nplt.xlabel(\"Energy (eV)\")\nplt.ylabel(\"Normalized XAS\")\nplt.legend()\n</code></pre> <p></p>"},{"location":"Getting_started_XAS.html#plotting-2d-spectra","title":"Plotting 2D Spectra","text":"<p>The 2D (time versus energy) data can be summed and plotted using the XSpecT visualation module.  First, from visualization the <code>XASVisualization</code> object is instantiated.  Then, using the <code>combine_spectra</code> method and passing the <code>xas</code> data object and the necessary data keys the data is processed.</p> <pre><code>v=XSpect.XSpect_Visualization.XASVisualization()\nv.combine_spectra(xas_analysis=xas,\n                  xas_laser_key='epix_simultaneous_laser_time_energy_binned',\n                  xas_key='epix_xray_not_laser_time_energy_binned',\n                  norm_laser_key='ipm_simultaneous_laser_time_energy_binned',\n                  norm_key='ipm_xray_not_laser_time_energy_binned')\n</code></pre> <p>Finally, the 2D spectrum can be plotted, setting vmin and vmax colorbar parameters as needed.</p> <pre><code>v.plot_2d_difference_spectrum(xas, vmin=-0.3, vmax=0.3)\n</code></pre> <p></p>"},{"location":"Getting_started_XES.html","title":"XES","text":"<pre><code>import h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import  rotate\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import curve_fit,minimize\nimport multiprocessing\nimport os\nfrom functools import partial\nimport time\nimport sys\nimport argparse\nfrom datetime import datetime\nimport tempfile\nimport XSpect.XSpect_Analysis\nimport XSpect.XSpect_Controller\nimport XSpect.XSpect_Visualization\n</code></pre>"},{"location":"Getting_started_XES.html#static-xes-spectra","title":"Static XES Spectra","text":"<pre><code>xes_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(hutch='mfx',experiment_id='mfxx1013623',lcls_run=23)\nxes=XSpect.XSpect_Controller.XESBatchAnalysisRotation()\nxes.key_epix=['epix_1/ROI_0_area']\n#xes.set_key_aliases(keys,names)\nxes.import_roi=[[523,535]]\nxes.rois=[[0,12]]\nxes.adu_cutoff=3.0\nxes.angle=0\nxes.transpose=True\nxes.run_parser(['37'])\nstart=time.time()\nxes.primary_analysis_parallel_range(4,xes_experiment,method=xes.primary_analysis_static,increment=2000,verbose=False)\nend=time.time()\nv=XSpect.XSpect_Visualization.XESVisualization()\nv.combine_static_spectra(xes_analysis=xes,xes_key='epix_ROI_1')\nplt.plot(v.summed_xes)\n</code></pre> <pre><code>Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:43&lt;00:00,  2.55s/Shot_Batch]\n\n[&lt;matplotlib.lines.Line2D at 0x7f0d8767e820&gt;]\n</code></pre>"},{"location":"Getting_started_XES.html#2d-time-resolved-xes-spectra","title":"2D Time-resolved XES Spectra","text":"<pre><code>xes_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(hutch='mfx',experiment_id='mfxl1027922',lcls_run=22)\nxes=XSpect.XSpect_Controller.XESBatchAnalysisRotation()\nkeys=['tt/ttCorr','epics/lxt', 'enc/lasDelay' , 'ipm4/sum','tt/AMPL'] \nnames=['time_tool_correction','lxt_ttc'  ,'encoder','ipm', 'time_tool_ampl']\n#Here we define the epix detector keys separately as they are imported separately to avoid OOM\nxes.key_epix=[r'epix_2/ROI_0_area']\nxes.friendly_name_epix=['epix']\n##\nxes.set_key_aliases(keys,names)\n#xes.end_index=5000\nxes.mintime=-0.9\nxes.maxtime=0.9\nxes.numpoints=40\nxes.time_bins=np.linspace(xes.mintime,xes.maxtime,xes.numpoints)\nxes.rois=[[0,50]]\nxes.adu_cutoff=3.0\nxes.angle=90\nxes.lxt_key=None\nxes.transpose=True\n#xes.add_filter('xray','ipm4',1.0E3)\n#xes.add_filter('simultaneous','ipm4',1.0E3)\nxes.add_filter('simultaneous','time_tool_ampl',0.05)\nxes.run_parser(['44-46'])\n</code></pre> <pre><code>start=time.time()\nxes.primary_analysis_parallel_range(8,xes_experiment,increment=1000,verbose=False)\nend=time.time()\n</code></pre> <pre><code>Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [02:25&lt;00:00,  4.85s/Shot_Batch]\n</code></pre> <pre><code>xes.status\n</code></pre> <pre><code>['Setting key aliases.',\n 'Adding filter: Shot Type=simultaneous, Filter Key=time_tool_ampl, Threshold=0.05',\n 'Parsing run array.',\n 'Starting parallel analysis with shot ranges.',\n 'Parsing run shots.',\n 'Run shots parsed.',\n 'Breaking into shot ranges with increment 1000.',\n 'Shot ranges broken.',\n 'Parallel analysis with shot ranges completed.',\n 'Parallel analysis completed.',\n 'Total time: 145.59 seconds.',\n 'Parallel time (processing): 145.59 seconds.',\n 'Time per batch (on average): 4.85 seconds.',\n 'Time per core (on average): 18.20 seconds.',\n 'Batches per core (on average): 3.75.',\n 'Read bytes: 13.14 MB.',\n 'Write bytes: 4055.88 MB.',\n 'Memory used: 52.87 MB.']\n</code></pre> <pre><code>v=XSpect.XSpect_Visualization.XESVisualization()\nv.combine_spectra(xes_analysis=xes,xes_key='epix_xray_not_laser_time_binned_ROI_1',xes_laser_key='epix_simultaneous_laser_time_binned_ROI_1')\nv.vmin=-0.006\nv.vmax=0.004\nv.plot_2d_difference_spectrum(xes)\nplt.xlim(-0.8,0.8)\n</code></pre> <pre><code>(-0.8, 0.8)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"Overview.html","title":"Overview","text":"<p>XSpecT follows the principles of Model-View-Controller in its design. It is written in python following the object-oriented programming paradigm. It is designed for analyzing X-ray absorption and emission spectroscopy data at X-ray free electron lasers and is currently in use at the LCLS. </p> <p>The XSPecT code is comprised of several main modules designed to handle the analysis, visualization and control processes. The controller handles i/o, analysis pipelines and parallelization. The analysis module performs the data manipulations (e.g. filtering, sorting and mathematical operations). The visualization module provides methods to easily generate 2D difference maps and other plots of interest. </p> <p>The over process is depicted in the following figure: </p>"},{"location":"XSpect_Analysis.html","title":"XSpect Analysis","text":""},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.bin_uniques--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key for which unique values are to be binned.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_detector_adu--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> float or list of float, optional <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_detector_adu--returns","title":"Returns","text":"<p>np.ndarray     The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_nan--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask.</p> str, optional <p>The key corresponding to the filter data (default is 'ipm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> str, optional <p>The key corresponding to the filter data (default is 'ipm'). </p> float, optional <p>The threshold value for filtering (default is 1.0E4).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel--parameters","title":"Parameters","text":"array_like <p>Array of shots</p> integer <p>Pixel point to be patched</p> string <p>Determines which mode to use for patching the pixel. Averaging works well.</p> integer <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> integer <p>Degree of polynomial if polynomial patching is used.</p> integer <p>Number of pixels to include in the polynomial or interpolation fitting</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel--returns","title":"Returns","text":"<p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel. Parameters</p> <p>data : array_like     Array of shots pixel : integer     Pixel point to be patched mode : string     Determined which mode to use for patching the pixel. Averaging works well. patch_range : integer     pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue. deg : integer     Degree of polynomial if polynomial patching is used. poly_range : integer     Number of pixels to include in the polynomial or interpolation fitting Returns</p> <p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str, optional <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> int, optional <p>The range around the pixel to use for patching (default is 4).</p> int, optional <p>The degree of the polynomial for polynomial patching (default is 1).</p> int, optional <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> int, optional <p>The axis along which to apply the patching (default is 1).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels_1d--parameters","title":"Parameters","text":"<p>run : spectroscopy_run     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. mode : str, optional     The mode of patching ('average', 'polynomial', or 'interpolate'). patch_range : int, optional     The range around the pixel to use for patching (default is 4). deg : int, optional     The degree of the polynomial for polynomial patching (default is 1). poly_range : int, optional     The range of pixels to use for polynomial or interpolation patching (default is 6).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.purge_keys--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> list of str <p>The list of keys to purge.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_spatial--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list, optional <p>The range of shots to consider (default is [0, None]).</p> list of lists, optional <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> function, optional <p>The function to apply for reduction (default is np.sum).</p> bool, optional <p>Whether to purge the original detector data after reduction (default is True).</p> bool, optional <p>Whether to combine ROIs (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the data within each bin (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.separate_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to separate.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.time_binning--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> array-like <p>The bins to use for time binning.</p> str, optional <p>The key for the laser time delay data (default is 'lxt_ttc').</p> str, optional <p>The key for the fast delay data (default is 'encoder').</p> str, optional <p>The key for the time tool correction data (default is 'time_tool_correction').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.union_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to combine.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.ccm_binning--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the CCM bins.</p> str, optional <p>The key corresponding to the CCM data (default is 'ccm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.make_ccm_axis--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> array-like <p>Array of energy values to be used for creating CCM bins.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the CCM bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> bool, optional <p>Whether to indicate that CCM is not being used (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm_temporal--parameters","title":"Parameters","text":"<p>run : object     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. timing_bin_key_indices : str     The key corresponding to the timing bin indices. ccm_bin_key_indices : str     The key corresponding to the CCM bin indices. average : bool, optional     Whether to average the reduced data (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.trim_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> int, optional <p>The minimum number of shots required to keep a CCM value (default is 120).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.make_energy_axis--parameters","title":"Parameters","text":"float <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> float <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> array-like <p>Array of pixels to determine the energy of.</p> float <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.normalize_xes--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of int, optional <p>The pixel range to sum over for normalization (default is [300, 550]).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.reduce_det_scanvar--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data within the run object.</p> str <p>The key corresponding to the scan variable indices.</p> str <p>The key corresponding to the scan variable bins.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.reduce_det_scanvar--returns","title":"Returns","text":"<p>None     The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.__init__--parameters","title":"Parameters","text":"str <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> str <p>Hutch name. Example: xcs</p> str <p>Experiment identifier. Example: xcsl1004021</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.get_experiment_directory--returns","title":"Returns","text":"<p>str     The directory of the experiment.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.get_experiment_directory--raises","title":"Raises","text":"<p>Exception     If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run","title":"<code>spectroscopy_run</code>","text":"<p>A class to represent a run within a spectroscopy experiment. Not an LCLS run.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_run:\n    \"\"\"\n    A class to represent a run within a spectroscopy experiment. Not an LCLS run. \n    \"\"\"\n    def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n        \"\"\"\n        Initializes a spectroscopy run instance.\n\n        Parameters\n        ----------\n\n        spec_experiment : spectroscopy_experiment\n            The parent spectroscopy experiment.\n\n        run : int\n            The run number.\n\n        verbose : bool, optional\n            Flag for verbose output used for printing all of the status updates. \n            These statuses are also available in the object itself. Defaults to False.\n\n        end_index : int, optional\n            Index to stop processing data. Defaults to -1.\n\n        start_index : int, optional\n            Index to start processing data. Defaults to 0.\n            These indices are used for batch analysis. \n\n        \"\"\"\n        self.spec_experiment=spec_experiment\n        self.run_number=run\n        self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n        self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n        self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n        self.verbose=verbose\n        self.end_index=end_index\n        self.start_index=start_index\n\n    def get_scan_val(self):\n        \"\"\"\n        Retrieves the scan variable from the HDF5 file of the run. \n        This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.scan_var=fh['scan/scan_variable']\n\n\n    def update_status(self,update):\n        \"\"\"\n        Updates the status log for the run and appends it to the objects status/datetime attibutes.\n        If verbose then it prints it.\n\n        Parameters\n        ----------\n\n        update : str\n            The status update message.\n\n        \"\"\"\n        self.status.append(update)\n        self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        if self.verbose:\n            print(update)\n\n    def get_run_shot_properties(self):\n        \"\"\"\n        Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n            xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n            laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n            self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.simultaneous=np.logical_and(self.xray,self.laser)\n\n        self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n        self.update_status('Obtained shot properties')\n    def set_arbitrary_filter(self,key='arbitrary_filter'):\n        self.verbose=False\n        with h5py.File(self.run_file, 'r') as fh:\n            self.arbitrary_filter = fh[key][self.start_index:self.end_index]\n\n    def load_run_keys(self, keys, friendly_names):\n        \"\"\"\n        Loads specified keys from the run file into memory.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load from the hdf5 file\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n        \"\"\"\n        start=time.time()\n        with h5py.File(self.run_file, 'r') as fh:\n            for key, name in zip(keys, friendly_names):\n\n                try:\n                    setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n                except KeyError as e:\n                    self.update_status('Key does not exist: %s' % e.args[0])\n                except MemoryError:\n                    setattr(self, name, fh[key])\n                    self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n        end=time.time()\n        self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n    def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n        \"\"\"\n        Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n        Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load.\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys.\n\n        transpose : bool, optional\n            Flag to transpose the loaded data. Defaults to False.\n\n        rois : list of lists, optional\n            List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n            Each ROI should be in the form [start_col, end_col].\n\n        combine : bool, optional\n            Whether to combine ROIs into a single mask. Defaults to True.\n\n        \"\"\"\n        start = time.time()\n        fh = h5py.File(self.run_file, 'r')\n\n        for key, name in zip(keys, friendly_names):\n            try:\n                # Load the data from the file for the given key\n                data = fh[key][self.start_index:self.end_index, :, :]\n\n                # Apply one-dimensional ROIs if specified\n                if rois is not None:\n                    if combine:\n                        # Combine multiple ROIs into a single mask\n                        mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                        for roi in rois:\n                            start_col, end_col = roi\n                            mask[start_col:end_col] = True\n                        # Apply the mask to select the ROI from the third dimension\n                        data = data[:, :, mask]\n                    else:\n                        # Handle each ROI separately, storing the results as different attributes\n                        for idx, roi in enumerate(rois):\n                            start_col, end_col = roi\n                            roi_data = data[:, :, start_col:end_col]\n                            setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n                setattr(self, name, data)\n\n                if transpose:\n                    setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n            except KeyError as e:\n                self.update_status(f'Key does not exist: {e.args[0]}')\n            except MemoryError:\n                setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n                self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n        end = time.time()\n        self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n        self.h5 = fh\n\n\n\n    def load_sum_run_scattering(self,key,low=20,high=80):\n        \"\"\"\n        Sums the scattering data across the specified range.\n\n        Parameters\n        ----------\n\n        key : str\n            The key to sum the scattering data from.\n\n        low : int\n            Low index for summing\n\n        high: int \n            high index for summing\n            These indices should be chosen over the water ring or some scattering of interest.\n\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n\n    def close_h5(self):\n        \"\"\"\n        Closes the HDF5 file handle.\n        Again, avoiding memory issues.\n        \"\"\"\n        self.h5.close()\n        del self.h5\n\n    def purge_all_keys(self,keys_to_keep):\n        \"\"\"\n        Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n        Parameters\n        ----------\n\n        keys_to_keep : list\n            List of keys to retain.\n\n        \"\"\"\n\n        new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n        self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.__init__","title":"<code>__init__(spec_experiment, run, verbose=False, end_index=-1, start_index=0)</code>","text":"<p>Initializes a spectroscopy run instance.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.__init__--parameters","title":"Parameters","text":"spectroscopy_experiment <p>The parent spectroscopy experiment.</p> int <p>The run number.</p> bool, optional <p>Flag for verbose output used for printing all of the status updates.  These statuses are also available in the object itself. Defaults to False.</p> int, optional <p>Index to stop processing data. Defaults to -1.</p> int, optional <p>Index to start processing data. Defaults to 0. These indices are used for batch analysis.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n    \"\"\"\n    Initializes a spectroscopy run instance.\n\n    Parameters\n    ----------\n\n    spec_experiment : spectroscopy_experiment\n        The parent spectroscopy experiment.\n\n    run : int\n        The run number.\n\n    verbose : bool, optional\n        Flag for verbose output used for printing all of the status updates. \n        These statuses are also available in the object itself. Defaults to False.\n\n    end_index : int, optional\n        Index to stop processing data. Defaults to -1.\n\n    start_index : int, optional\n        Index to start processing data. Defaults to 0.\n        These indices are used for batch analysis. \n\n    \"\"\"\n    self.spec_experiment=spec_experiment\n    self.run_number=run\n    self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n    self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n    self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n    self.verbose=verbose\n    self.end_index=end_index\n    self.start_index=start_index\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.close_h5","title":"<code>close_h5()</code>","text":"<p>Closes the HDF5 file handle. Again, avoiding memory issues.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def close_h5(self):\n    \"\"\"\n    Closes the HDF5 file handle.\n    Again, avoiding memory issues.\n    \"\"\"\n    self.h5.close()\n    del self.h5\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.get_run_shot_properties","title":"<code>get_run_shot_properties()</code>","text":"<p>Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_run_shot_properties(self):\n    \"\"\"\n    Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n        xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n        laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n        self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.simultaneous=np.logical_and(self.xray,self.laser)\n\n    self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n    self.update_status('Obtained shot properties')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.get_scan_val","title":"<code>get_scan_val()</code>","text":"<p>Retrieves the scan variable from the HDF5 file of the run.  This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_scan_val(self):\n    \"\"\"\n    Retrieves the scan variable from the HDF5 file of the run. \n    This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.scan_var=fh['scan/scan_variable']\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_key_delayed","title":"<code>load_run_key_delayed(keys, friendly_names, transpose=False, rois=None, combine=True)</code>","text":"<p>Loads specified keys from the run file into memory without immediate conversion to numpy arrays.  Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_key_delayed--parameters","title":"Parameters","text":"list <p>List of keys to load.</p> list <p>Corresponding list of friendly names for the keys.</p> bool, optional <p>Flag to transpose the loaded data. Defaults to False.</p> list of lists, optional <p>List of ROIs (regions of interest) as pixel ranges along one dimension (default is None). Each ROI should be in the form [start_col, end_col].</p> bool, optional <p>Whether to combine ROIs into a single mask. Defaults to True.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n    \"\"\"\n    Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n    Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load.\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys.\n\n    transpose : bool, optional\n        Flag to transpose the loaded data. Defaults to False.\n\n    rois : list of lists, optional\n        List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n        Each ROI should be in the form [start_col, end_col].\n\n    combine : bool, optional\n        Whether to combine ROIs into a single mask. Defaults to True.\n\n    \"\"\"\n    start = time.time()\n    fh = h5py.File(self.run_file, 'r')\n\n    for key, name in zip(keys, friendly_names):\n        try:\n            # Load the data from the file for the given key\n            data = fh[key][self.start_index:self.end_index, :, :]\n\n            # Apply one-dimensional ROIs if specified\n            if rois is not None:\n                if combine:\n                    # Combine multiple ROIs into a single mask\n                    mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                    for roi in rois:\n                        start_col, end_col = roi\n                        mask[start_col:end_col] = True\n                    # Apply the mask to select the ROI from the third dimension\n                    data = data[:, :, mask]\n                else:\n                    # Handle each ROI separately, storing the results as different attributes\n                    for idx, roi in enumerate(rois):\n                        start_col, end_col = roi\n                        roi_data = data[:, :, start_col:end_col]\n                        setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n            setattr(self, name, data)\n\n            if transpose:\n                setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n        except KeyError as e:\n            self.update_status(f'Key does not exist: {e.args[0]}')\n        except MemoryError:\n            setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n            self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n    end = time.time()\n    self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n    self.h5 = fh\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_keys","title":"<code>load_run_keys(keys, friendly_names)</code>","text":"<p>Loads specified keys from the run file into memory.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_keys--parameters","title":"Parameters","text":"list <p>List of keys to load from the hdf5 file</p> list <p>Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_keys(self, keys, friendly_names):\n    \"\"\"\n    Loads specified keys from the run file into memory.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load from the hdf5 file\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n    \"\"\"\n    start=time.time()\n    with h5py.File(self.run_file, 'r') as fh:\n        for key, name in zip(keys, friendly_names):\n\n            try:\n                setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n            except KeyError as e:\n                self.update_status('Key does not exist: %s' % e.args[0])\n            except MemoryError:\n                setattr(self, name, fh[key])\n                self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n    end=time.time()\n    self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_sum_run_scattering","title":"<code>load_sum_run_scattering(key, low=20, high=80)</code>","text":"<p>Sums the scattering data across the specified range.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_sum_run_scattering--parameters","title":"Parameters","text":"str <p>The key to sum the scattering data from.</p> int <p>Low index for summing</p> int <p>high index for summing These indices should be chosen over the water ring or some scattering of interest.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_sum_run_scattering(self,key,low=20,high=80):\n    \"\"\"\n    Sums the scattering data across the specified range.\n\n    Parameters\n    ----------\n\n    key : str\n        The key to sum the scattering data from.\n\n    low : int\n        Low index for summing\n\n    high: int \n        high index for summing\n        These indices should be chosen over the water ring or some scattering of interest.\n\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.purge_all_keys","title":"<code>purge_all_keys(keys_to_keep)</code>","text":"<p>Purges all keys from the object except those specified. Again avoid OOM in the analyis object.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.purge_all_keys--parameters","title":"Parameters","text":"list <p>List of keys to retain.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_all_keys(self,keys_to_keep):\n    \"\"\"\n    Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n    Parameters\n    ----------\n\n    keys_to_keep : list\n        List of keys to retain.\n\n    \"\"\"\n\n    new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n    self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.update_status","title":"<code>update_status(update)</code>","text":"<p>Updates the status log for the run and appends it to the objects status/datetime attibutes. If verbose then it prints it.</p>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.update_status--parameters","title":"Parameters","text":"str <p>The status update message.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def update_status(self,update):\n    \"\"\"\n    Updates the status log for the run and appends it to the objects status/datetime attibutes.\n    If verbose then it prints it.\n\n    Parameters\n    ----------\n\n    update : str\n        The status update message.\n\n    \"\"\"\n    self.status.append(update)\n    self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n    if self.verbose:\n        print(update)\n</code></pre>"},{"location":"XSpect_Controller.html","title":"XSpect Controller","text":""},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.bin_uniques--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key for which unique values are to be binned.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_detector_adu--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> float or list of float, optional <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_detector_adu--returns","title":"Returns","text":"<p>np.ndarray     The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_nan--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask.</p> str, optional <p>The key corresponding to the filter data (default is 'ipm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> str, optional <p>The key corresponding to the filter data (default is 'ipm'). </p> float, optional <p>The threshold value for filtering (default is 1.0E4).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel--parameters","title":"Parameters","text":"array_like <p>Array of shots</p> integer <p>Pixel point to be patched</p> string <p>Determines which mode to use for patching the pixel. Averaging works well.</p> integer <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> integer <p>Degree of polynomial if polynomial patching is used.</p> integer <p>Number of pixels to include in the polynomial or interpolation fitting</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel--returns","title":"Returns","text":"<p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel. Parameters</p> <p>data : array_like     Array of shots pixel : integer     Pixel point to be patched mode : string     Determined which mode to use for patching the pixel. Averaging works well. patch_range : integer     pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue. deg : integer     Degree of polynomial if polynomial patching is used. poly_range : integer     Number of pixels to include in the polynomial or interpolation fitting Returns</p> <p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str, optional <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> int, optional <p>The range around the pixel to use for patching (default is 4).</p> int, optional <p>The degree of the polynomial for polynomial patching (default is 1).</p> int, optional <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> int, optional <p>The axis along which to apply the patching (default is 1).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels_1d--parameters","title":"Parameters","text":"<p>run : spectroscopy_run     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. mode : str, optional     The mode of patching ('average', 'polynomial', or 'interpolate'). patch_range : int, optional     The range around the pixel to use for patching (default is 4). deg : int, optional     The degree of the polynomial for polynomial patching (default is 1). poly_range : int, optional     The range of pixels to use for polynomial or interpolation patching (default is 6).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.purge_keys--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> list of str <p>The list of keys to purge.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_spatial--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list, optional <p>The range of shots to consider (default is [0, None]).</p> list of lists, optional <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> function, optional <p>The function to apply for reduction (default is np.sum).</p> bool, optional <p>Whether to purge the original detector data after reduction (default is True).</p> bool, optional <p>Whether to combine ROIs (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the data within each bin (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.separate_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to separate.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.time_binning--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> array-like <p>The bins to use for time binning.</p> str, optional <p>The key for the laser time delay data (default is 'lxt_ttc').</p> str, optional <p>The key for the fast delay data (default is 'encoder').</p> str, optional <p>The key for the time tool correction data (default is 'time_tool_correction').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.union_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to combine.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.ccm_binning--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the CCM bins.</p> str, optional <p>The key corresponding to the CCM data (default is 'ccm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.make_ccm_axis--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> array-like <p>Array of energy values to be used for creating CCM bins.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the CCM bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> bool, optional <p>Whether to indicate that CCM is not being used (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm_temporal--parameters","title":"Parameters","text":"<p>run : object     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. timing_bin_key_indices : str     The key corresponding to the timing bin indices. ccm_bin_key_indices : str     The key corresponding to the CCM bin indices. average : bool, optional     Whether to average the reduced data (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.trim_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> int, optional <p>The minimum number of shots required to keep a CCM value (default is 120).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.make_energy_axis--parameters","title":"Parameters","text":"float <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> float <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> array-like <p>Array of pixels to determine the energy of.</p> float <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.normalize_xes--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of int, optional <p>The pixel range to sum over for normalization (default is [300, 550]).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.reduce_det_scanvar--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data within the run object.</p> str <p>The key corresponding to the scan variable indices.</p> str <p>The key corresponding to the scan variable bins.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.reduce_det_scanvar--returns","title":"Returns","text":"<p>None     The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.__init__--parameters","title":"Parameters","text":"str <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> str <p>Hutch name. Example: xcs</p> str <p>Experiment identifier. Example: xcsl1004021</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.get_experiment_directory--returns","title":"Returns","text":"<p>str     The directory of the experiment.</p>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.get_experiment_directory--raises","title":"Raises","text":"<p>Exception     If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Diagnostics.html","title":"XSpect Diagnostics","text":""},{"location":"XSpect_PostProcessing.html","title":"XSpect PostProcessing","text":""},{"location":"XSpect_Visualization.html","title":"XSpect Visualization","text":""},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.bin_uniques--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key for which unique values are to be binned.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_detector_adu--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> float or list of float, optional <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_detector_adu--returns","title":"Returns","text":"<p>np.ndarray     The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_nan--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask.</p> str, optional <p>The key corresponding to the filter data (default is 'ipm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> str, optional <p>The key corresponding to the filter data (default is 'ipm'). </p> float, optional <p>The threshold value for filtering (default is 1.0E4).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel--parameters","title":"Parameters","text":"array_like <p>Array of shots</p> integer <p>Pixel point to be patched</p> string <p>Determines which mode to use for patching the pixel. Averaging works well.</p> integer <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> integer <p>Degree of polynomial if polynomial patching is used.</p> integer <p>Number of pixels to include in the polynomial or interpolation fitting</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel--returns","title":"Returns","text":"<p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel. Parameters</p> <p>data : array_like     Array of shots pixel : integer     Pixel point to be patched mode : string     Determined which mode to use for patching the pixel. Averaging works well. patch_range : integer     pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue. deg : integer     Degree of polynomial if polynomial patching is used. poly_range : integer     Number of pixels to include in the polynomial or interpolation fitting Returns</p> <p>float     The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str, optional <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> int, optional <p>The range around the pixel to use for patching (default is 4).</p> int, optional <p>The degree of the polynomial for polynomial patching (default is 1).</p> int, optional <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> int, optional <p>The axis along which to apply the patching (default is 1).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels_1d--parameters","title":"Parameters","text":"<p>run : spectroscopy_run     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. mode : str, optional     The mode of patching ('average', 'polynomial', or 'interpolate'). patch_range : int, optional     The range around the pixel to use for patching (default is 4). deg : int, optional     The degree of the polynomial for polynomial patching (default is 1). poly_range : int, optional     The range of pixels to use for polynomial or interpolation patching (default is 6).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.purge_keys--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> list of str <p>The list of keys to purge.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_spatial--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list, optional <p>The range of shots to consider (default is [0, None]).</p> list of lists, optional <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> function, optional <p>The function to apply for reduction (default is np.sum).</p> bool, optional <p>Whether to purge the original detector data after reduction (default is True).</p> bool, optional <p>Whether to combine ROIs (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the data within each bin (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.separate_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to separate.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.time_binning--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> array-like <p>The bins to use for time binning.</p> str, optional <p>The key for the laser time delay data (default is 'lxt_ttc').</p> str, optional <p>The key for the fast delay data (default is 'encoder').</p> str, optional <p>The key for the time tool correction data (default is 'time_tool_correction').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.union_shots--parameters","title":"Parameters","text":"spectroscopy_run <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of str <p>The list of filter keys to combine.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.ccm_binning--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the CCM bins.</p> str, optional <p>The key corresponding to the CCM data (default is 'ccm').</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.make_ccm_axis--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> array-like <p>Array of energy values to be used for creating CCM bins.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the CCM bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> bool, optional <p>Whether to indicate that CCM is not being used (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm_temporal--parameters","title":"Parameters","text":"<p>run : object     The spectroscopy run instance. detector_key : str     The key corresponding to the detector data. timing_bin_key_indices : str     The key corresponding to the timing bin indices. ccm_bin_key_indices : str     The key corresponding to the CCM bin indices. average : bool, optional     Whether to average the reduced data (default is True).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_temporal--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> str <p>The key corresponding to the timing bin indices.</p> bool, optional <p>Whether to average the reduced data (default is False).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.trim_ccm--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> int, optional <p>The minimum number of shots required to keep a CCM value (default is 120).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.make_energy_axis--parameters","title":"Parameters","text":"float <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> float <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> array-like <p>Array of pixels to determine the energy of.</p> float <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.normalize_xes--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data.</p> list of int, optional <p>The pixel range to sum over for normalization (default is [300, 550]).</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.reduce_det_scanvar--parameters","title":"Parameters","text":"object <p>The spectroscopy run instance.</p> str <p>The key corresponding to the detector data within the run object.</p> str <p>The key corresponding to the scan variable indices.</p> str <p>The key corresponding to the scan variable bins.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.reduce_det_scanvar--returns","title":"Returns","text":"<p>None     The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.__init__--parameters","title":"Parameters","text":"str <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> str <p>Hutch name. Example: xcs</p> str <p>Experiment identifier. Example: xcsl1004021</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.get_experiment_directory--returns","title":"Returns","text":"<p>str     The directory of the experiment.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.get_experiment_directory--raises","title":"Raises","text":"<p>Exception     If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run","title":"<code>spectroscopy_run</code>","text":"<p>A class to represent a run within a spectroscopy experiment. Not an LCLS run.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_run:\n    \"\"\"\n    A class to represent a run within a spectroscopy experiment. Not an LCLS run. \n    \"\"\"\n    def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n        \"\"\"\n        Initializes a spectroscopy run instance.\n\n        Parameters\n        ----------\n\n        spec_experiment : spectroscopy_experiment\n            The parent spectroscopy experiment.\n\n        run : int\n            The run number.\n\n        verbose : bool, optional\n            Flag for verbose output used for printing all of the status updates. \n            These statuses are also available in the object itself. Defaults to False.\n\n        end_index : int, optional\n            Index to stop processing data. Defaults to -1.\n\n        start_index : int, optional\n            Index to start processing data. Defaults to 0.\n            These indices are used for batch analysis. \n\n        \"\"\"\n        self.spec_experiment=spec_experiment\n        self.run_number=run\n        self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n        self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n        self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n        self.verbose=verbose\n        self.end_index=end_index\n        self.start_index=start_index\n\n    def get_scan_val(self):\n        \"\"\"\n        Retrieves the scan variable from the HDF5 file of the run. \n        This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.scan_var=fh['scan/scan_variable']\n\n\n    def update_status(self,update):\n        \"\"\"\n        Updates the status log for the run and appends it to the objects status/datetime attibutes.\n        If verbose then it prints it.\n\n        Parameters\n        ----------\n\n        update : str\n            The status update message.\n\n        \"\"\"\n        self.status.append(update)\n        self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        if self.verbose:\n            print(update)\n\n    def get_run_shot_properties(self):\n        \"\"\"\n        Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n            xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n            laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n            self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.simultaneous=np.logical_and(self.xray,self.laser)\n\n        self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n        self.update_status('Obtained shot properties')\n    def set_arbitrary_filter(self,key='arbitrary_filter'):\n        self.verbose=False\n        with h5py.File(self.run_file, 'r') as fh:\n            self.arbitrary_filter = fh[key][self.start_index:self.end_index]\n\n    def load_run_keys(self, keys, friendly_names):\n        \"\"\"\n        Loads specified keys from the run file into memory.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load from the hdf5 file\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n        \"\"\"\n        start=time.time()\n        with h5py.File(self.run_file, 'r') as fh:\n            for key, name in zip(keys, friendly_names):\n\n                try:\n                    setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n                except KeyError as e:\n                    self.update_status('Key does not exist: %s' % e.args[0])\n                except MemoryError:\n                    setattr(self, name, fh[key])\n                    self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n        end=time.time()\n        self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n    def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n        \"\"\"\n        Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n        Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load.\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys.\n\n        transpose : bool, optional\n            Flag to transpose the loaded data. Defaults to False.\n\n        rois : list of lists, optional\n            List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n            Each ROI should be in the form [start_col, end_col].\n\n        combine : bool, optional\n            Whether to combine ROIs into a single mask. Defaults to True.\n\n        \"\"\"\n        start = time.time()\n        fh = h5py.File(self.run_file, 'r')\n\n        for key, name in zip(keys, friendly_names):\n            try:\n                # Load the data from the file for the given key\n                data = fh[key][self.start_index:self.end_index, :, :]\n\n                # Apply one-dimensional ROIs if specified\n                if rois is not None:\n                    if combine:\n                        # Combine multiple ROIs into a single mask\n                        mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                        for roi in rois:\n                            start_col, end_col = roi\n                            mask[start_col:end_col] = True\n                        # Apply the mask to select the ROI from the third dimension\n                        data = data[:, :, mask]\n                    else:\n                        # Handle each ROI separately, storing the results as different attributes\n                        for idx, roi in enumerate(rois):\n                            start_col, end_col = roi\n                            roi_data = data[:, :, start_col:end_col]\n                            setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n                setattr(self, name, data)\n\n                if transpose:\n                    setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n            except KeyError as e:\n                self.update_status(f'Key does not exist: {e.args[0]}')\n            except MemoryError:\n                setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n                self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n        end = time.time()\n        self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n        self.h5 = fh\n\n\n\n    def load_sum_run_scattering(self,key,low=20,high=80):\n        \"\"\"\n        Sums the scattering data across the specified range.\n\n        Parameters\n        ----------\n\n        key : str\n            The key to sum the scattering data from.\n\n        low : int\n            Low index for summing\n\n        high: int \n            high index for summing\n            These indices should be chosen over the water ring or some scattering of interest.\n\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n\n    def close_h5(self):\n        \"\"\"\n        Closes the HDF5 file handle.\n        Again, avoiding memory issues.\n        \"\"\"\n        self.h5.close()\n        del self.h5\n\n    def purge_all_keys(self,keys_to_keep):\n        \"\"\"\n        Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n        Parameters\n        ----------\n\n        keys_to_keep : list\n            List of keys to retain.\n\n        \"\"\"\n\n        new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n        self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.__init__","title":"<code>__init__(spec_experiment, run, verbose=False, end_index=-1, start_index=0)</code>","text":"<p>Initializes a spectroscopy run instance.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.__init__--parameters","title":"Parameters","text":"spectroscopy_experiment <p>The parent spectroscopy experiment.</p> int <p>The run number.</p> bool, optional <p>Flag for verbose output used for printing all of the status updates.  These statuses are also available in the object itself. Defaults to False.</p> int, optional <p>Index to stop processing data. Defaults to -1.</p> int, optional <p>Index to start processing data. Defaults to 0. These indices are used for batch analysis.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n    \"\"\"\n    Initializes a spectroscopy run instance.\n\n    Parameters\n    ----------\n\n    spec_experiment : spectroscopy_experiment\n        The parent spectroscopy experiment.\n\n    run : int\n        The run number.\n\n    verbose : bool, optional\n        Flag for verbose output used for printing all of the status updates. \n        These statuses are also available in the object itself. Defaults to False.\n\n    end_index : int, optional\n        Index to stop processing data. Defaults to -1.\n\n    start_index : int, optional\n        Index to start processing data. Defaults to 0.\n        These indices are used for batch analysis. \n\n    \"\"\"\n    self.spec_experiment=spec_experiment\n    self.run_number=run\n    self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n    self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n    self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n    self.verbose=verbose\n    self.end_index=end_index\n    self.start_index=start_index\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.close_h5","title":"<code>close_h5()</code>","text":"<p>Closes the HDF5 file handle. Again, avoiding memory issues.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def close_h5(self):\n    \"\"\"\n    Closes the HDF5 file handle.\n    Again, avoiding memory issues.\n    \"\"\"\n    self.h5.close()\n    del self.h5\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.get_run_shot_properties","title":"<code>get_run_shot_properties()</code>","text":"<p>Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_run_shot_properties(self):\n    \"\"\"\n    Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n        xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n        laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n        self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.simultaneous=np.logical_and(self.xray,self.laser)\n\n    self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n    self.update_status('Obtained shot properties')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.get_scan_val","title":"<code>get_scan_val()</code>","text":"<p>Retrieves the scan variable from the HDF5 file of the run.  This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_scan_val(self):\n    \"\"\"\n    Retrieves the scan variable from the HDF5 file of the run. \n    This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.scan_var=fh['scan/scan_variable']\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_key_delayed","title":"<code>load_run_key_delayed(keys, friendly_names, transpose=False, rois=None, combine=True)</code>","text":"<p>Loads specified keys from the run file into memory without immediate conversion to numpy arrays.  Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_key_delayed--parameters","title":"Parameters","text":"list <p>List of keys to load.</p> list <p>Corresponding list of friendly names for the keys.</p> bool, optional <p>Flag to transpose the loaded data. Defaults to False.</p> list of lists, optional <p>List of ROIs (regions of interest) as pixel ranges along one dimension (default is None). Each ROI should be in the form [start_col, end_col].</p> bool, optional <p>Whether to combine ROIs into a single mask. Defaults to True.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n    \"\"\"\n    Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n    Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load.\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys.\n\n    transpose : bool, optional\n        Flag to transpose the loaded data. Defaults to False.\n\n    rois : list of lists, optional\n        List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n        Each ROI should be in the form [start_col, end_col].\n\n    combine : bool, optional\n        Whether to combine ROIs into a single mask. Defaults to True.\n\n    \"\"\"\n    start = time.time()\n    fh = h5py.File(self.run_file, 'r')\n\n    for key, name in zip(keys, friendly_names):\n        try:\n            # Load the data from the file for the given key\n            data = fh[key][self.start_index:self.end_index, :, :]\n\n            # Apply one-dimensional ROIs if specified\n            if rois is not None:\n                if combine:\n                    # Combine multiple ROIs into a single mask\n                    mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                    for roi in rois:\n                        start_col, end_col = roi\n                        mask[start_col:end_col] = True\n                    # Apply the mask to select the ROI from the third dimension\n                    data = data[:, :, mask]\n                else:\n                    # Handle each ROI separately, storing the results as different attributes\n                    for idx, roi in enumerate(rois):\n                        start_col, end_col = roi\n                        roi_data = data[:, :, start_col:end_col]\n                        setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n            setattr(self, name, data)\n\n            if transpose:\n                setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n        except KeyError as e:\n            self.update_status(f'Key does not exist: {e.args[0]}')\n        except MemoryError:\n            setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n            self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n    end = time.time()\n    self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n    self.h5 = fh\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_keys","title":"<code>load_run_keys(keys, friendly_names)</code>","text":"<p>Loads specified keys from the run file into memory.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_keys--parameters","title":"Parameters","text":"list <p>List of keys to load from the hdf5 file</p> list <p>Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_keys(self, keys, friendly_names):\n    \"\"\"\n    Loads specified keys from the run file into memory.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load from the hdf5 file\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n    \"\"\"\n    start=time.time()\n    with h5py.File(self.run_file, 'r') as fh:\n        for key, name in zip(keys, friendly_names):\n\n            try:\n                setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n            except KeyError as e:\n                self.update_status('Key does not exist: %s' % e.args[0])\n            except MemoryError:\n                setattr(self, name, fh[key])\n                self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n    end=time.time()\n    self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_sum_run_scattering","title":"<code>load_sum_run_scattering(key, low=20, high=80)</code>","text":"<p>Sums the scattering data across the specified range.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_sum_run_scattering--parameters","title":"Parameters","text":"str <p>The key to sum the scattering data from.</p> int <p>Low index for summing</p> int <p>high index for summing These indices should be chosen over the water ring or some scattering of interest.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_sum_run_scattering(self,key,low=20,high=80):\n    \"\"\"\n    Sums the scattering data across the specified range.\n\n    Parameters\n    ----------\n\n    key : str\n        The key to sum the scattering data from.\n\n    low : int\n        Low index for summing\n\n    high: int \n        high index for summing\n        These indices should be chosen over the water ring or some scattering of interest.\n\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.purge_all_keys","title":"<code>purge_all_keys(keys_to_keep)</code>","text":"<p>Purges all keys from the object except those specified. Again avoid OOM in the analyis object.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.purge_all_keys--parameters","title":"Parameters","text":"list <p>List of keys to retain.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_all_keys(self,keys_to_keep):\n    \"\"\"\n    Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n    Parameters\n    ----------\n\n    keys_to_keep : list\n        List of keys to retain.\n\n    \"\"\"\n\n    new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n    self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.update_status","title":"<code>update_status(update)</code>","text":"<p>Updates the status log for the run and appends it to the objects status/datetime attibutes. If verbose then it prints it.</p>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.update_status--parameters","title":"Parameters","text":"str <p>The status update message.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def update_status(self,update):\n    \"\"\"\n    Updates the status log for the run and appends it to the objects status/datetime attibutes.\n    If verbose then it prints it.\n\n    Parameters\n    ----------\n\n    update : str\n        The status update message.\n\n    \"\"\"\n    self.status.append(update)\n    self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n    if self.verbose:\n        print(update)\n</code></pre>"}]}