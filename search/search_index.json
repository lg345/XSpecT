{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>XSpecT is an analysis software package designed for ultrafast x-ray free electron laser experiments. It is written in python following the principles of object-oriented programming.</p>"},{"location":"index.html#installation","title":"Installation","text":"<p>The source code is available for download from the XSpecT github repo.</p>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>Check out our quick start examples for XAS and XES, as well as the example jupyter noteboks found here.</p>"},{"location":"index.html#license","title":"License","text":"<p>Copyright 2025 XSpecT Team</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \u201cSoftware\u201d), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \u201cAS IS\u201d, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"Getting_started_XAS.html","title":"XAS","text":""},{"location":"Getting_started_XAS.html#importing-dependencies","title":"Importing Dependencies","text":"<p>XSpecT relies on a number of common python packages including:  </p> <ul> <li>h5py for reading HDF5 files</li> <li>NumPy and scipy for data analysis</li> <li>Matplotlib for visualization</li> <li>Other system related packages</li> </ul> <p>Depending on your system you may need to install the necessary dependencies. S3DF users should have the necessary packages by default.</p> <pre><code>import h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import rotate\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import curve_fit,minimize\nimport multiprocessing\nimport os\nfrom functools import partial\nimport time\nimport sys\nimport argparse\nfrom datetime import datetime\nimport tempfile\n</code></pre>"},{"location":"Getting_started_XAS.html#importing-xspect-modules","title":"Importing XSPecT Modules","text":"<p>XSpecT has several main modules for function to control various aspects of the analysis, visualization, diagnostics and overall processing.</p> <pre><code>sys.path.insert(0, './XSpecT/')\nimport XSpect.XSpect_Analysis\nimport XSpect.XSpect_Controller\nimport XSpect.XSpect_Visualization\nimport XSpect.XSpect_PostProcessing\nimport XSpect.XSpect_Diagnostics\n</code></pre>"},{"location":"Getting_started_XAS.html#xas-analysis-example","title":"XAS Analysis Example","text":""},{"location":"Getting_started_XAS.html#setting-up-experiment-parameters","title":"Setting up experiment parameters","text":"<p>Initializing the <code>spectroscopy_experiment</code> class and setting the relevant experiment information<code>lslc_run</code>, <code>hutch</code>, and <code>experiment_id</code> parameters.</p> <pre><code>xas_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(lcls_run=22, hutch='xcs', experiment_id='xcsl1030422')\n</code></pre> <p>These values will be used to obtain the directory for the data which is stored in <code>experiment_directory</code>:</p> <pre><code>xas_experiment.experiment_directory\n</code></pre> <pre><code>'/sdf/data/lcls/ds/xcs/xcsl1030422/hdf5/smalldata'\n</code></pre>"},{"location":"Getting_started_XAS.html#xasbatchanalysis-class","title":"XASBatchAnalysis Class","text":"<p>Instantiating the <code>XASBatchAnalysis</code> class which allows you to set attributes relevant to the analysis such as the HDF5 group keys for the various datasets, filter thresholds, and timing/energy parameters. The class also contain an analysis pipeline method, which controls the sequence of analysis operations.</p> <pre><code>xas=XSpect.XSpect_Controller.XASBatchAnalysis()\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-keys-and-aliases","title":"Setting keys and aliases","text":"<p>The keys, which specify the data to read from the HDF5 file, are defined as a list of strings. For pump-probe XAS measurements this typically includes: </p> <ul> <li>The monochromator energy and set values (epics/ccm_E, epicsUser/ccm_E_setpoint)</li> <li>TT correction values and amplitude (tt/ttCorr, tt/AMPL)</li> <li>Timing stage values (epics/lxt_ttc)</li> <li>Emission CCD detecotr ROI sum values (epix_2/ROI_0_sum)</li> <li>Normalization channel (ipm4/sum).</li> </ul> <p>Their \"friendly\" names serve as an easier to remember alias for the keys and are also defined as a list of strings with the same ordering as the keys. These lists are passed to <code>set_key_aliases</code> which creates the key aliases.</p> <pre><code>keys=['epics/ccm_E', 'epicsUser/ccm_E_setpoint', 'tt/ttCorr', 'epics/lxt_ttc', 'enc/lasDelay', 'ipm4/sum', 'tt/AMPL', 'epix_2/ROI_0_sum'] \nnames=['ccm', 'ccm_E_setpoint', 'time_tool_correction', 'lxt_ttc', 'encoder', 'ipm', 'time_tool_ampl', 'epix']\nxas.set_key_aliases(keys,names)\n</code></pre>"},{"location":"Getting_started_XAS.html#adding-filters","title":"Adding filters","text":"<p>Filters are set using <code>add_filter</code> which takes requires the parameters \\'shot_type\\' (e.g. xray, simultaneous), \\'filter_key\\' (i.e. which dataset to apply the filter to), and the filter threshold.</p> <pre><code>xas.add_filter('xray','ipm',500.0)\nxas.add_filter('simultaneous','ipm',500.0)\nxas.add_filter('simultaneous','time_tool_ampl',0.01)\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-runs","title":"Setting runs","text":"<p>Multiple runs (files) can be analyzed and combined into a single data set using the <code>run_parser</code> method.  Specify the runs as a list of strings or as a single string with space separated run numbers.  Ranges can be specified using numbers separated by a \"-\".</p> <pre><code>xas.run_parser(['240-243 245-254'])\n</code></pre>"},{"location":"Getting_started_XAS.html#setting-timing-parameters","title":"Setting timing parameters","text":"<p>Delay timing range and number of points is set in picoseconds.</p> <pre><code>xas.mintime = -0.5\nxas.maxtime = 2.0\nxas.numpoints = 25\n</code></pre>"},{"location":"Getting_started_XAS.html#normalization-option","title":"Normalization option","text":"<p>Normalization is set by default (False) to use an IPM sum dataset. Alternatively, the scattering liquid ring signal can be used:</p> <pre><code>xas.scattering = True\n</code></pre>"},{"location":"Getting_started_XAS.html#running-analysis-loop","title":"Running Analysis Loop","text":"<p>With the necessary parameters set the analysis procedure can be initiatilized. Here you pass the experiment attributes from <code>xas_experiment</code>. For details of the step by step analysis processes set <code>verbose= True</code> (False is the default).</p> <pre><code>xas.primary_analysis_loop(xas_experiment, verbose=True)\n</code></pre> <pre><code>Obtained shot properties\nHDF5 import of keys completed. Time: 0.02 seconds\nMask: xray has been filtered on ipm by minimum threshold: 500.000\nShots removed: 2645\nMask: simultaneous has been filtered on ipm by minimum threshold: 500.000\nShots removed: 1904\nMask: simultaneous has been filtered on time_tool_ampl by minimum threshold: 0.010\nShots removed: 100\nShots combined for detector epix on filters: simultaneous and laser into epix_simultaneous_laser\nShots (12182) separated for detector epix on filters: xray and laser into epix_xray_laser\nShots combined for detector ipm on filters: simultaneous and laser into ipm_simultaneous_laser\nShots (12182) separated for detector ipm on filters: xray and laser into ipm_xray_laser\nShots combined for detector ccm on filters: simultaneous and laser into ccm_simultaneous_laser\nShots (12182) separated for detector ccm on filters: xray and laser into ccm_xray_laser\nGenerated timing bins from -0.500000 to 2.000000 in 25 steps.\nGenerated ccm bins from 7.105000 to 7.156500 in 54 steps.\nShots combined for detector timing_bin_indices on filters: simultaneous and laser into timing_bin_indices_simultaneous_laser\nShots (12182) separated for detector timing_bin_indices on filters: xray and laser into timing_bin_indices_xray_laser\nShots combined for detector ccm_bin_indices on filters: simultaneous and laser into ccm_bin_indices_simultaneous_laser\nShots (12182) separated for detector ccm_bin_indices on filters: xray and laser into ccm_bin_indices_xray_laser\nDetector epix_simultaneous_laser binned in time into key: epix_simultaneous_laser_time_energy_binned\nDetector epix_xray_not_laser binned in time into key: epix_xray_not_laser_time_energy_binned\nDetector ipm_simultaneous_laser binned in time into key: ipm_simultaneous_laser_time_energy_binned\nDetector ipm_xray_not_laser binned in time into key: ipm_xray_not_laser_time_energy_binned\nObtained shot properties\nHDF5 import of keys completed. Time: 0.03 seconds\n...\n</code></pre>"},{"location":"Getting_started_XAS.html#exploring-analyzed-runs","title":"Exploring Analyzed Runs","text":"<p>The data for each run is stored in <code>analyzed_runs</code> list.</p> <pre><code>xas.analyzed_runs\n</code></pre> <pre><code>[&lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2ea00&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6de1d00&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe71fe580&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fab670&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe75ac550&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe75c4280&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fc07f0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b1f0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b460&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fb5e80&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6fb53d0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6d2b9d0&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe6b00c10&gt;,\n &lt;XSpect.XSpect_Analysis.spectroscopy_run at 0x7febe72de340&gt;]\n</code></pre> <p>We can check the data shape for the laser-off shots first analyzed run, which has the dimensions of 25 time bins by 54 energy bins.</p> <pre><code>print(\"Data shape:\", xas.analyzed_runs[0].epix_xray_not_laser_time_energy_binned.shape)\n</code></pre> <pre><code>Data shape: (25, 54)\n</code></pre> <p>Since the laser the laser is off, we can average across all time bins for the epix and normalization channels.</p> <pre><code>y = np.average(xas.analyzed_runs[0].epix_xray_not_laser_time_energy_binned, axis = 0)\nnorm = np.average(xas.analyzed_runs[0].ipm_xray_not_laser_time_energy_binned, axis =0)\n</code></pre>"},{"location":"Getting_started_XAS.html#plotting-laser-off-spectrum","title":"Plotting Laser-off Spectrum","text":"<p>Then the laser off spectrum can be plotted versus the monochromator energies.</p> <pre><code>plt.plot(xas.analyzed_runs[0].ccm_energies, y/norm, label=\"Laser-off\")\nplt.xlabel(\"Energy (eV)\")\nplt.ylabel(\"Normalized XAS\")\nplt.legend()\n</code></pre> <p></p>"},{"location":"Getting_started_XAS.html#plotting-2d-spectra","title":"Plotting 2D Spectra","text":"<p>The 2D (time versus energy) data can be summed and plotted using the XSpecT visualation module.  First, from visualization the <code>XASVisualization</code> object is instantiated.  Then, using the <code>combine_spectra</code> method and passing the <code>xas</code> data object and the necessary data keys the data is processed.</p> <pre><code>v=XSpect.XSpect_Visualization.XASVisualization()\nv.combine_spectra(xas_analysis=xas,\n                  xas_laser_key='epix_simultaneous_laser_time_energy_binned',\n                  xas_key='epix_xray_not_laser_time_energy_binned',\n                  norm_laser_key='ipm_simultaneous_laser_time_energy_binned',\n                  norm_key='ipm_xray_not_laser_time_energy_binned')\n</code></pre> <p>Finally, the 2D spectrum can be plotted, setting vmin and vmax colorbar parameters as needed.</p> <pre><code>v.plot_2d_difference_spectrum(xas, vmin=-0.3, vmax=0.3)\n</code></pre> <p></p>"},{"location":"Getting_started_XES.html","title":"XES","text":"<pre><code>import h5py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import  rotate\nfrom scipy.interpolate import interp1d\nfrom scipy.optimize import curve_fit,minimize\nimport multiprocessing\nimport os\nfrom functools import partial\nimport time\nimport sys\nimport argparse\nfrom datetime import datetime\nimport tempfile\nimport XSpect.XSpect_Analysis\nimport XSpect.XSpect_Controller\nimport XSpect.XSpect_Visualization\n</code></pre>"},{"location":"Getting_started_XES.html#static-xes-spectra","title":"Static XES Spectra","text":"<pre><code>xes_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(hutch='mfx',experiment_id='mfxx1013623',lcls_run=23)\nxes=XSpect.XSpect_Controller.XESBatchAnalysisRotation()\nxes.key_epix=['epix_1/ROI_0_area']\n#xes.set_key_aliases(keys,names)\nxes.import_roi=[[523,535]]\nxes.rois=[[0,12]]\nxes.adu_cutoff=3.0\nxes.angle=0\nxes.transpose=True\nxes.run_parser(['37'])\nstart=time.time()\nxes.primary_analysis_parallel_range(4,xes_experiment,method=xes.primary_analysis_static,increment=2000,verbose=False)\nend=time.time()\nv=XSpect.XSpect_Visualization.XESVisualization()\nv.combine_static_spectra(xes_analysis=xes,xes_key='epix_ROI_1')\nplt.plot(v.summed_xes)\n</code></pre> <pre><code>Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 17/17 [00:43&lt;00:00,  2.55s/Shot_Batch]\n\n[&lt;matplotlib.lines.Line2D at 0x7f0d8767e820&gt;]\n</code></pre>"},{"location":"Getting_started_XES.html#2d-time-resolved-xes-spectra","title":"2D Time-resolved XES Spectra","text":"<pre><code>xes_experiment = XSpect.XSpect_Analysis.spectroscopy_experiment(hutch='mfx',experiment_id='mfxl1027922',lcls_run=22)\nxes=XSpect.XSpect_Controller.XESBatchAnalysisRotation()\nkeys=['tt/ttCorr','epics/lxt', 'enc/lasDelay' , 'ipm4/sum','tt/AMPL'] \nnames=['time_tool_correction','lxt_ttc'  ,'encoder','ipm', 'time_tool_ampl']\n#Here we define the epix detector keys separately as they are imported separately to avoid OOM\nxes.key_epix=[r'epix_2/ROI_0_area']\nxes.friendly_name_epix=['epix']\n##\nxes.set_key_aliases(keys,names)\n#xes.end_index=5000\nxes.mintime=-0.9\nxes.maxtime=0.9\nxes.numpoints=40\nxes.time_bins=np.linspace(xes.mintime,xes.maxtime,xes.numpoints)\nxes.rois=[[0,50]]\nxes.adu_cutoff=3.0\nxes.angle=90\nxes.lxt_key=None\nxes.transpose=True\n#xes.add_filter('xray','ipm4',1.0E3)\n#xes.add_filter('simultaneous','ipm4',1.0E3)\nxes.add_filter('simultaneous','time_tool_ampl',0.05)\nxes.run_parser(['44-46'])\n</code></pre> <pre><code>start=time.time()\nxes.primary_analysis_parallel_range(8,xes_experiment,increment=1000,verbose=False)\nend=time.time()\n</code></pre> <pre><code>Processing: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30/30 [02:25&lt;00:00,  4.85s/Shot_Batch]\n</code></pre> <pre><code>xes.status\n</code></pre> <pre><code>['Setting key aliases.',\n 'Adding filter: Shot Type=simultaneous, Filter Key=time_tool_ampl, Threshold=0.05',\n 'Parsing run array.',\n 'Starting parallel analysis with shot ranges.',\n 'Parsing run shots.',\n 'Run shots parsed.',\n 'Breaking into shot ranges with increment 1000.',\n 'Shot ranges broken.',\n 'Parallel analysis with shot ranges completed.',\n 'Parallel analysis completed.',\n 'Total time: 145.59 seconds.',\n 'Parallel time (processing): 145.59 seconds.',\n 'Time per batch (on average): 4.85 seconds.',\n 'Time per core (on average): 18.20 seconds.',\n 'Batches per core (on average): 3.75.',\n 'Read bytes: 13.14 MB.',\n 'Write bytes: 4055.88 MB.',\n 'Memory used: 52.87 MB.']\n</code></pre> <pre><code>v=XSpect.XSpect_Visualization.XESVisualization()\nv.combine_spectra(xes_analysis=xes,xes_key='epix_xray_not_laser_time_binned_ROI_1',xes_laser_key='epix_simultaneous_laser_time_binned_ROI_1')\nv.vmin=-0.006\nv.vmax=0.004\nv.plot_2d_difference_spectrum(xes)\nplt.xlim(-0.8,0.8)\n</code></pre> <pre><code>(-0.8, 0.8)\n</code></pre> <pre><code>\n</code></pre>"},{"location":"Overview.html","title":"XSpecT","text":"<p>XSpecT follows the principles of Model-View-Controller in its design. It is written in python following the object-oriented programming paradigm. It is designed for analyzing X-ray absorption and emission spectroscopy data at X-ray free electron lasers and is currently in use at the LCLS. </p> <p>The XSPecT code is comprised of several main modules designed to handle the analysis, visualization and control processes. The controller handles i/o, analysis pipelines and parallelization. The analysis module performs the data manipulations (e.g. filtering, sorting and mathematical operations). The visualization module provides methods to easily generate 2D difference maps and other plots of interest. </p> <p>The over process is depicted in the following figure: </p>"},{"location":"Post_Processing.html","title":"Post_Processing","text":""},{"location":"Post_Processing.html#fxn-irfconv","title":"FXN: irfconv","text":"<ul> <li>Performs numerical convolution between heaviside exponential function and gaussian IRF (gaussian area normalized to 1)</li> <li>Inputs:<ul> <li>x = x axis (time)</li> <li>k = list or array of exponential rate constants (can have more than one)</li> <li>center = center position of gaussian IRF (will define \"time zero\")</li> <li>sigma = standard deviation of gaussian IRF</li> <li>amp = amplitude for scaling the function (optional, default will be 1)</li> </ul> </li> <li>Outputs:<ul> <li>The function gives a 2D array back: the first dimension will be that of the provided x grid (time), the second dimension will be # of k values given; i.e. a matrix where each column is a convolved monoexponential function with rate constant k[i]</li> </ul> </li> <li>Function accepts an array of x axis values along which it returns the convolved function<ul> <li>From these values, it generates a new array of linearly spaced x values along which to perform the convolution<ul> <li>I increase the maximum time over which the convolution is evaluated beyond the original x axis to avoid numerical truncation effects (sometimes seen at the end of the convolution)</li> <li>I also increase the number of steps along the x axis by a factor of 10: if the time binning is too coarse (say you have time bins of 200 fs, but are trying to describe a gaussian IRF with sigma = 100 fs), the normalization will not work correctly (even just testing numerical integration of the normalized gaussian function, you approach an area value of 1 only once you have sufficient sampling along the x axis)<ul> <li>From a data perspective, having time binning sufficiently larger than your IRF width kind of nullifies the effect of the IRF in the first place, but from a fitting/analysis perspective, fitting functions might steer the IRF sigma to values smaller than your time steps in the absence of constraints, which would cause unexpected swings in amplitudes that can affect your fit; ensuring excess sampling in the convolution grid should help to avoid this problem and maintain reasonable normalization</li> </ul> </li> </ul> </li> </ul> </li> <li>The heaviside exponential function and normalized gaussian are evaluated over the convolution x grid and then numerically convolved using scipy.signal.fftconvolve</li> <li>If two vectors of length m and length n are convolved, the resulting convolution vector will be of length m+n-1, so we need to effectively extract the portion of the convolution containing our signal and then interpolate that portion back onto our original time axis<ul> <li>Want to test how this works with non-linearly binned input time (x axis) values</li> </ul> </li> <li>Example code to visualize effect of varying sigma on shape of function near time zero:</li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\n</code></pre> <pre><code>pana = XSpect.XSpect_PostProcessing.post_analysis()\nk1 = [0.08] ## rate constant (ps^-1^)\nirf_t0 = 0 ## time zero\nt = np.linspace(-20, 100, 1921) ## time vector (in ps)\nirfsig_list = [0, 0.1, 0.2, 0.5, 0.8] ## IRF sigma values\nkpl = plt.cm.get_cmap('cet_bmy', len(irfsig_list)*2)\nbmy = kpl(range(10))\n</code></pre> <pre><code>for i in range(len(irfsig_list)):\n    plt.plot(t, pana.**irfconv**(t, k1, irf_t0, irfsig_list[i]), color = bmy[i,:])\n</code></pre> <p><pre><code>plt.xlim([-3, 5])\nplt.legend(irfsig_list, title = r'$IRF sigma$')\nplt.xlabel('Time (ps)')\nplt.ylabel('Amplitude')\nplt.title('Gaussian IRF Convolution (Numerical)')\nplt.show()\n</code></pre> </p>"},{"location":"Post_Processing.html#fxn-irfconv_ana","title":"FXN: irfconv_ana","text":"<ul> <li>Evaluates analytical expression for the convolution of exponential and gaussian functions</li> <li>Inputs:<ul> <li>x = array of x values (time)</li> <li>k = list or array of exponential rate constants</li> <li>center = time zero</li> <li>sigma = gaussian IRF standard deviation</li> <li>amp = amplitudes for scaling</li> </ul> </li> <li>Outputs:<ul> <li>The function gives a 2D array back: the first dimension will be that of the provided x grid (time), the second dimension will be # of k values given; i.e. a matrix where each column is a convolved monoexponential function with rate constant k[i]</li> </ul> </li> <li>Analytical expression:  <ul> <li>A = amplitude</li> <li>k = exponential rate constant</li> <li>t~<sub>0</sub> = \"time zero\"</li> <li>\ud835\udf48 = gaussian IRF standard deviation/width parameter</li> <li>erf is the error function</li> </ul> </li> <li>I have the code return the heaviside exponential function if \ud835\udf48 = 0 is provided with time zero shifted to value given by \"center\"</li> <li>Example code to visualize effect of varying sigma on shape of function near time zero (and check that it is consistent with numerical results):</li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\n</code></pre> <pre><code>k1 = [0.08]\nirf_t0 = 0\nt = np.linspace(-20, 100, 1921)\nirfsig_list = [0, 0.1, 0.2, 0.5, 0.8]\nkpl = plt.cm.get_cmap('cet_bmy', len(irfsig_list)*2)\nbmy = kpl(range(10))\npana = XSpect.XSpect_PostProcessing.post_analysis()\n</code></pre> <pre><code>for i in range(len(irfsig_list)):\n    plt.plot(t, pana.**irfconv_ana**(t, k1, irf_t0, irfsig_list[i]), color = bmy[i,:])\n</code></pre> <p><pre><code>plt.xlim([-3, 5])\nplt.legend(irfsig_list, title = r'$IRF sigma$')\nplt.xlabel('Time (ps)')\nplt.ylabel('Amplitude')\nplt.title('Gaussian IRF Convolution (Analytical)')\nplt.show()\n</code></pre> </p>"},{"location":"Post_Processing.html#fxn-kmatsolver","title":"FXN: kmatsolver","text":"<ul> <li>Function solves a system of rate equations purely composed of unimolecular (first-order) steps; in these cases, the analytical solution exists and can be found using the eigenvectors/values of the rate constant (k) matrix; building block of global/target kinetic analysis fitting</li> <li>Inputs:<ul> <li>kmatrix = function mapping k values to an np.array modeling the desired k matrix</li> <li>x = array of x values (time)</li> <li>k = list or array of exponential rate constants</li> <li>X0 = initial conditions (which species has what population at t=0, given as a list or array)</li> <li>center = time zero</li> <li>sigma = gaussian IRF standard deviation</li> <li>irf_option = 'numerical' (default), 'analytical', or 'none' determines which function to evaluate exponentials with (irfconv, irfconv_ana, and expfunc_heaviside respectively)</li> <li>printopt = True (default), prints k matrix (when calling this function iteratively, say in a fitting algorithm, I set this to False)</li> </ul> </li> <li>Outputs:<ul> <li>The function gives a 2D array back: each i<sup>th</sup> column represents the concentration profile of the i<sup>th</sup> species in the kinetic model evaluated over the given x values</li> </ul> </li> <li>Example code solving a sequential system of kinetic equations: $$ (A \\dashrightarrow B \\dashrightarrow C \\dashrightarrow decays) $$</li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\n</code></pre> <pre><code>pana = XSpect.XSpect_PostProcessing.post_analysis()\n</code></pre> <pre><code>k1 = [0.08, 0.01, 0.002] ## rate constants\nirf_c = 0 ## time zero\nirf_sig = 0.2 ## IRF std dev (ps)\n</code></pre> <pre><code>t = np.linspace(-20, 800, 1641) # time (ps)\n</code></pre> <pre><code>X0 = [1, 0, 0] # initial conditions, at time zero, 1st species is at full population and 2nd and 3rd have no population\n</code></pre> <pre><code>Km = lambda x: np.array([(-x[0], 0, 0), (x[0], -x[1], 0), (0, x[1], -x[2])]) ## K matrix as a lambda fxn, in kmatsolver will take k list as an input and generate the appropriate K matrix\n</code></pre> <p><pre><code>C = pana.**kmatsolver**(Km, t, k1, X0, irf_c, irf_sig)\nplt.plot(t, C, linewidth = 2)\nplt.xlabel('Time (ps)')\nplt.ylabel('Amplitude')\nplt.xlim([min(t), max(t)])\nplt.legend(['Species 1', 'Species 2', 'Species 3'])\nplt.title('kmatsolver Results')\nplt.show()\n</code></pre> </p> <ul> <li> </li> </ul> <pre><code>import matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\n</code></pre> <pre><code>pana = XSpect.XSpect_PostProcessing.post_analysis()\n</code></pre> <pre><code>## let\\'s simulate some data first to do SVD on\nprint(\\'Simulating dataset:\\')\n</code></pre> <pre><code>## first we\\'ll simulate our C(t) matrix (C_sim)\nt = np.linspace(-20, 500, 4000)\nk_sim = [0.08, 0.01]\nirf_t0 = 0.5\nirf_sig = 0.15\nX0_sim = [1, 0]\nKm = lambda x:np.array([(-x[0], 0), (x[0], -x[1])])\nC_sim = pana.kmatsolver(Km, t, k_sim, X0_sim, irf_t0, irf_sig)\n</code></pre> <pre><code>## then will simulate some gaussian \"spectra\" (spec_sim)\nenergy = np.linspace(7030, 7080, (7080-7030)*5)\nspec_x = [7050, 7055]\nspec_sigma = [5, 6, 4]\nspec_amp = [0.8, 0.9, 0.85]\nspec_sim = np.empty([len(energy), len(spec_x)])\nfor i in range(len(spec_x)):\nspec_sim[:,i] = spec_amp[i]*pana.gaussfunc(energy, spec_x[i],\nspec_sigma[i])\n</code></pre> <pre><code>## calculate full data matrix (A_sim) and add noise\nA = C_sim@np.transpose(spec_sim)\nnoise = np.random.normal(loc = 0, scale = 0.2, size = (len(t),\nlen(energy)))\nA_sim = A + noise\n</code></pre> <pre><code>## Plot simulated data (C_sim(t), spec_sim(energy), A_sim(t, energy))\nplotmax = np.max(np.abs(A_sim))\ncontlevels = np.linspace(-plotmax, plotmax, 100)\nfig, ax = plt.subplots(ncols = 3, nrows = 1, figsize = (15, 5))\n</code></pre> <pre><code>p1 = ax[0].plot(t, C_sim, linewidth = 2)\nax[0].set_xlabel('Time')\nax[0].set_ylabel('Amplitude')\nax[0].set_xlim([min(t), max(t)])\nax[0].set_title('C_sim')\n</code></pre> <pre><code>p2 = ax[1].plot(energy, spec_sim, linewidth = 2)\nax[1].set_xlabel('Energy')\nax[1].set_ylabel('Amplitude')\nax[1].set_xlim([min(energy), max(energy)])\nax[1].set_title('spec_sim')\n</code></pre> <pre><code>p3 = ax[2].contourf(energy, t, A_sim, contlevels, cmap = 'RdBu')\nax[2].set_xlabel('Energy')\nax[2].set_ylabel('Time')\nax[2].set_title('A_sim')\ncb = fig.colorbar(p3, ax = ax[2])\n</code></pre> <p><pre><code>plt.show()\nprint('Running svdplot:')\nncomp = 4\npana.**svdplot**(t, energy, A_sim, ncomp)\n</code></pre> </p> <ul> <li> </li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\n</code></pre> <pre><code>pana = XSpect.XSpect_PostProcessing.post_analysis()\n</code></pre> <pre><code>## let's simulate some data first to do SVD on\nprint('Simulating dataset:')\n</code></pre> <pre><code>## first we'll simulate our C(t) matrix (C_sim)\nt = np.linspace(-20, 500, 4000)\nk_sim = [0.08, 0.01]\nirf_t0 = 0.5\nirf_sig = 0.15\nX0_sim = [1, 0]\nKm = lambda x:np.array([(-x[0], 0), (x[0], -x[1])])\nC_sim = pana.kmatsolver(Km, t, k_sim, X0_sim, irf_t0, irf_sig)\n</code></pre> <pre><code>## then will simulate some gaussian \"spectra\" (spec_sim)\nenergy = np.linspace(7030, 7080, (7080-7030)\\*5)\nspec_x = [7050, 7055]\nspec_sigma = [5, 6, 4]\nspec_amp = [0.8, 0.9, 0.85]\nspec_sim = np.empty([len(energy), len(spec_x)])\nfor i in range(len(spec_x)):\nspec_sim[:,i] = spec_amp[i]*pana.gaussfunc(energy, spec_x[i],\nspec_sigma[i])\n</code></pre> <pre><code>## calculate full data matrix (A_sim) and add noise\nA = C_sim@np.transpose(spec_sim)\nnoise = np.random.normal(loc = 0, scale = 0.2, size = (len(t),\nlen(energy)))\nA_sim = A + noise\n</code></pre> <pre><code>## Plot simulated data (C_sim(t), spec_sim(energy), A_sim(t, energy))\nplotmax = np.max(np.abs(A_sim))\ncontlevels = np.linspace(-plotmax, plotmax, 100)\nfig, ax = plt.subplots(ncols = 3, nrows = 1, figsize = (15, 5))\n</code></pre> <pre><code>p1 = ax[0].plot(t, C_sim, linewidth = 2)\nax[0].set_xlabel('Time')\nax[0].set_ylabel('Amplitude')\nax[0].set_xlim([min(t), max(t)])\nax[0].set_title('C_sim')\n</code></pre> <pre><code>p2 = ax[1].plot(energy, spec_sim, linewidth = 2)\nax[1].set_xlabel('Energy')\nax[1].set_ylabel('Amplitude')\nax[1].set_xlim([min(energy), max(energy)])\nax[1].set_title('spec_sim')\n</code></pre> <pre><code>p3 = ax[2].contourf(energy, t, A_sim, contlevels, cmap = 'RdBu')\nax[2].set_xlabel('Energy')\nax[2].set_ylabel('Time')\nax[2].set_title('A_sim')\ncb = fig.colorbar(p3, ax = ax[2])\nplt.show()\n</code></pre> <pre><code>print('Running svdreconstruct:')\nncomp = 2\nA_filt = pana.**svdreconstruct**(A_sim, ncomp)\n</code></pre> <pre><code>fig, ax = plt.subplots(ncols = 2, nrows = 1, figsize = (15,5))\np1 = ax[0].contourf(energy, t, A_filt, contlevels, cmap = 'RdBu')\nax[0].set_xlabel('Energy')\nax[0].set_ylabel('Time')\nax[0].set_title('Data Reconstructed')\ncb = fig.colorbar(p1, ax = ax[0])\n</code></pre> <p><pre><code>index_cut = np.argmin(np.abs(energy - 7050))\nax[1].plot(A_sim[:, index_cut])\nax[1].plot(A_filt[:, index_cut])\nax[1].set_xlabel('Time')\nax[1].set_ylabel('Amplitude')\nax[1].set_title('Data vs SVD Filtered Data')\nax[1].legend(['A_sim', 'A_filt'])\nplt.show()\n</code></pre> </p> <ul> <li> </li> <li> </li> <li> </li> <li>**Example of a bound dictionary (bd) that targetanalysis_run can accept; the overarching dictionary contains two lower level dictionaries, one for lower bounds ('lb') and one for upper bounds ('ub'); the lower/upper bounds for every parameter is then given in list form under the appropriate key</li> </ul> <p>bd = {'lb': {'k': [0, 0], 'center': [-10], 'sigma': [0]},  'ub': {'k': [np.inf, np.inf], 'center': [10], 'sigma': [1]}}</p> <ul> <li>Given the considerations above, I provide a set of default bounds<ul> <li>For every rate constant guess provided, a set of [0 to np.inf] bounds are given, indicating that the k will always be positive (and does away with the symmetry around zero problem)</li> <li>For irf center (t0) parameter, the default is unconstrained [-np.inf to np.inf]</li> <li>For irf sigma (linewidth) parameter, the default is constrained [0 to np.inf]</li> </ul> </li> <li>Currently these are the only two options for targetanalysis_run -     the default constraints and user supplied constraints, can add     option for fully unconstrained though this could lead to some     issues</li> <li>Currently the only way to \"fix\" parameters in the fit would be to     use the bound dictionary format provided above and set the lower     and upper bound for a given parameter to be equal to the desired     \"fixed\" value, may be sufficient, will look into options</li> <li>I do not have an implementation yet for calculating standard errors     from the fit (though the output of scipy.optimize.least_squares     returns a jacobian, which can be used to estimate the Hessian and     by extension the covariance matrix of the parameters)... will     work on</li> <li>Example where a 2D data set in time and energy is simulated and then the target analysis fitting protocol is run (using a bound dictionary):</li> </ul> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport colorcet.plotting as cc\nimport XSpect.XSpect_PostProcessing\npana = XSpect.XSpect_PostProcessing.post_analysis()\n</code></pre> <pre><code>## let's simulate some data to test the fitting on first\nprint('Simulating dataset:')\n</code></pre> <pre><code>## first we'll simulate our C(t) matrix (C_sim)\nt = np.linspace(-20, 500, 4000)\nk_sim = [0.08, 0.01]\nirf_t0 = 0.5\nirf_sig = 0.15\nX0_sim = [1, 0]\nKm = lambda x:np.array([(-x[0], 0), (x[0], -x[1])])\nC_sim = pana.kmatsolver(Km, t, k_sim, X0_sim, irf_t0, irf_sig)\n</code></pre> <pre><code>## then will simulate some gaussian \"spectra\" (spec_sim)\nenergy = np.linspace(7030, 7080, (7080-7030)*5)\nspec_x = [7050, 7055]\nspec_sigma = [5, 6, 4]\nspec_amp = [0.8, 0.9, 0.85]\nspec_sim = np.empty([len(energy), len(spec_x)])\nfor i in range(len(spec_x)):\nspec_sim[:,i] = spec_amp[i]*pana.gaussfunc(energy, spec_x[i],\nspec_sigma[i])\n</code></pre> <pre><code>## calculate full data matrix (A_sim) and add noise\nA = C_sim@np.transpose(spec_sim)\nnoise = np.random.normal(loc = 0, scale = 0.2, size = (len(t),\nlen(energy)))\nA_sim = A + noise\n</code></pre> <pre><code>## Plot simulated data (C_sim(t), spec_sim(energy), A_sim(t, energy))\nplotmax = np.max(np.abs(A_sim))\ncontlevels = np.linspace(-plotmax, plotmax, 100)\nfig, ax = plt.subplots(ncols = 3, nrows = 1, figsize = (15, 7))\np1 = ax[0].plot(t, C_sim, linewidth = 2)\nax[0].set_xlabel('Time')\nax[0].set_ylabel('Amplitude')\nax[0].set_xlim([min(t), max(t)])\nax[0].set_title('C_sim')\np2 = ax[1].plot(energy, spec_sim, linewidth = 2)\nax[1].set_xlabel('Energy')\nax[1].set_ylabel('Amplitude')\nax[1].set_xlim([min(energy), max(energy)])\nax[1].set_title('spec_sim')\np3 = ax[2].contourf(energy, t, A_sim, contlevels, cmap = 'RdBu')\nax[2].set_xlabel('Energy')\nax[2].set_ylabel('Time')\nax[2].set_title('A_sim')\ncb = fig.colorbar(p3, ax = ax[2])\nplt.show()\n</code></pre> <pre><code>## now that we have a data set to fit, we'll set up a guess\n## this includes starting points for fit parameters (k and irf)\n## as well as a kinetic model to use (the k matrix defined in K_guess)\n</code></pre> <pre><code>## and run the fitting procedure\nprint('Running fitting protocol:')\nk_guess = [0.2, 0.001]\nirf_t0_guess = [0]\nirf_sigma_guess = [1]\nK_guess = lambda x:np.array([(-x[0], 0), (x[0], -x[1])])\nX0_guess = [1, 0]\nbd = {'lb': {'k': [0, 0], 'center': [-10], 'sigma': [0]}, 'ub': {'k': [np.inf, np.inf], 'center': [10],\n'sigma': [1]}}\nfit, C_fit, spec_fit = pana.**targetanalysis_run**(A_sim, t, K_guess,\nk_guess, irf_t0_guess, irf_sigma_guess, X0_guess, y = energy,\nbounds_dict = bd)\n</code></pre> <p></p> <p></p>"},{"location":"Post_Processing.html#fxn-svdplot","title":"FXN: svdplot","text":"<ul> <li>Performs singular value decomposition (SVD) and plots user defined number of left singular vectors, singular values, right singular vectors</li> <li>Inputs:<ul> <li>xval = x axis</li> <li>yval = y axis</li> <li>data = 2D data set to perform SVD on</li> <li>ncomp = number of components to plot</li> </ul> </li> <li>Outputs:<ul> <li>Plots ncomp left and right singular values and scree plot of     singular values</li> </ul> </li> <li>Example code using svdplot, we will simulate a dataset using two spectra with a sequential kinetic model and added noise then plot the first 4 components of the SVD (we should only expect 2 with significant singular values and structure in the singular vectors)</li> </ul>"},{"location":"Post_Processing.html#fxn-svdreconstruct","title":"FXN: svdreconstruct","text":"<ul> <li>Performs SVD reconstruction (filtering) on data using the first n components of the SVD</li> <li>Inputs:<ul> <li>data = data set to perform SVD and SVD filtering on</li> <li>ncomp = number of components to use to reconstruct the dataset from the SVD</li> </ul> </li> <li>Outputs:<ul> <li>A_filt = 2D array containing the SVD reconstructed dataset</li> </ul> </li> <li>Example code using SVD reconstruction for filtering out noise:</li> </ul>"},{"location":"Post_Processing.html#fxn-varproj","title":"FXN: varproj","text":"<ul> <li>Performs variable projection using a kinetic model and a provided data set; building block of global/target kinetic analysis fitting</li> <li>Inputs:<ul> <li>kmatrix = function mapping k values to an np.array modeling the desired k matrix</li> <li>x = array of x values (time)</li> <li>k = list or array of exponential rate constants</li> <li>X0 = initial conditions (which species has what population at t=0, given as a list or array)</li> <li>center = time zero</li> <li>sigma = gaussian IRF standard deviation</li> <li>data = experimental data on which you are performing variable projection</li> </ul> </li> <li>Outputs:<ul> <li>C = matrix of concentration column vectors</li> <li>E = matrix of decay/evolution/species associated spectra (projected from data)</li> <li>SimA = simulated data matrix using kinetic model and variable projection<ul> <li>We really only need SimA to calculate residuals for a fitting algorithm, but getting C and E as outputs is useful once we want to visualize the final results of the fit</li> </ul> </li> </ul> </li> <li>Workflow:<ul> <li>In variable projection method we assume a bilinear relationship between time and energy variables (they are separable): $$ A(t,\\lambda)\\  = \\ C(t)E^{T}(\\lambda) $$<ul> <li>Matrix form of Beer-Lambert Law where \\(C(t)\\) is a matrix of column vectors containing time-dependent concentrations of a given species and \\(E^{T}(\\lambda)\\) is a matrix of row vectors containing energy-dependent spectra of a given species<ul> <li>Note: the way that I have defined this means that by default the expected dimensions of the data matrix A will be 1st dimension (rows) = time and 2nd dimension (columns) = energy</li> </ul> </li> </ul> </li> <li>We generally choose one set of variables to parameterize for fitting (often time, i.e. kinetic modelling). The other set of variables are taken as linearly conditional on the parameterized set<ul> <li>The spectral vectors in \\(E\\) are projected from the experimental data using the calculated concentration vectors \\(C\\); \\(pinv()\\) is the Moore-Penrose pseudo inverse $$ pinv(C)A\\  = \\ pinv(C)CE^{T} $$ $$ E^{T} = \\ pinv(C)A $$</li> </ul> </li> <li>The simulated data set can then be constructed as follows: $$ A_{\\text{sim}} = C_{\\text{sim}}E^{T} = C_{\\text{sim}}pinv(C_{\\text{sim}})A_{\\exp} $$<ul> <li>This can then be used to calculate residuals in a global/target kinetic analysis objective function</li> </ul> </li> </ul> </li> </ul>"},{"location":"Post_Processing.html#fxn-targetobjective","title":"FXN: targetobjective","text":"<ul> <li>Target analysis objective function, takes parameter vector as     primary input, calculates simulated data using parameters     defined in theta, and returns residuals</li> <li>Inputs:<ul> <li>theta = vector containing parameters to be optimized in fit</li> <li>x = array of x values (time)</li> <li>kmatrix = function mapping k values to an np.array modeling     the desired k matrix</li> <li>x = array of x values (time)</li> <li>X0 = initial conditions (which species has what population     at t=0, given as a list or array)</li> <li>theta_parser = dictionary of parameters generated from     function \"parse_theta\", tells us how to read theta and map     to function inputs</li> <li>data = experimental data to be fit</li> </ul> </li> <li>Outputs:<ul> <li>A 1D array containing residuals of the experimental data     minus data simulated via the function \"varproj\"</li> </ul> </li> <li>Workflow:<ul> <li>The variables in the vector theta are sorted into a new     dictionary based on the structure of theta_parser</li> <li>These variables are then passed to the varproj function to     calculate simulated data matrix given the kinetic model     supplied</li> <li>The residuals are calculated and then sorted into a 1D array</li> </ul> </li> </ul>"},{"location":"Post_Processing.html#fxn-targetanalysis_run","title":"FXN: targetanalysis_run","text":"<ul> <li>Running target kinetic analysis using the     scipy.optimize.least_squares function</li> <li>Inputs:<ul> <li>data = experimental data to fit</li> <li>x = array of x values (time)</li> <li>kmatrix = function mapping k values to an np.array modeling     the desired k matrix</li> <li>k_in = list or array of initial guess exponential rate     constants</li> <li>center_in = initial guess time zero</li> <li>sigma_in = initial guess gaussian IRF standard deviation</li> <li>X0_in = initial conditions (which species has what     population at t=0, given as a list or array) for kinetic     model</li> <li>y = array of y values, energy (optional)</li> <li>bounds_dict = dictionary of parameter constraints (optional,     see below)</li> </ul> </li> <li>Outputs:<ul> <li>res_lsq = object containing the fit results from     scipy.optimize.least_squares run</li> <li>C_fit = concentration matrix calculated using fitted     parameters</li> <li>E_fit = decay/evolution/species associated spectra     calculated using fitted parameters<ul> <li>Additional outputs include:<ul> <li>Printing dictionary containing fitted parameters</li> <li>Printing final cost function from least squares at     optimized position (taken from res_lsq.cost, seems     to be printing residual sum of squares divided     by 2)</li> <li>Plotting concentration profiles and     decay/evolution/species associated spectra of each     component</li> </ul> </li> </ul> </li> </ul> </li> <li>Workflow:<ul> <li>The support functions parse_theta are used to package k_in,     center_in, and sigma_in into a dictionary format that can     be used to map the variables to (construct_theta) and from     (read_theta) the parameter vector (theta) that will be     provided to scipy.optimize.least_squares</li> <li>Parameter constraints are set if an appropriate bound     dictionary is provided, otherwise default constraints are     applied</li> <li>The fitting algorithm is run using the target objective     function, the generated parameter vector (theta), and the     other inputs necessary for target objective function</li> <li>The fit parameters are read out into a dictionary that is     printed</li> <li>The final cost of the least squares function is printed</li> <li>The fitted concentration profiles and     decay/evolution/species associated spectra are plotted</li> </ul> </li> <li>Some quirks:<ul> <li>In the exponential functions, I take the absolute value of     the given k values to ensure exponential decay, i.e.<ul> <li>fxn = a*exp(-kt)<ul> <li>For exponential decay, k will always be positive</li> </ul> </li> <li>I think this is the most likely case we will encounter     in chemical kinetics, if we need a more general     approach we can change this</li> <li>This means that for fitting, there are symmetries in the     error surface around zero for the rate constant     parameters<ul> <li>Using Levenberg-Marquardt or trust region reflective     implementations in scipy.optimize.least_squares,     this usually doesn't pose too much of a problem in     the sense that the correct value of rate constant     is usually attained, but not the necessarily the     sign</li> </ul> </li> </ul> </li> <li>The Levenberg-Marquardt implementation in     scipy.optimize.least_squares does not support parameter     constraints, in order to include this, I use the default     trust region reflective method<ul> <li>Users can supply a \"bound dictionary\" to define the     lower and upper bounds for parameters; I've     arbitrarily had this take the form below:</li> </ul> </li> </ul> </li> </ul>"},{"location":"XSpect_Analysis.html","title":"XSpect Analysis","text":""},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>key</code> <code>str</code> <p>The key for which unique values are to be binned.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>adu_threshold</code> <code>float or list of float</code> <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p> <code>3.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask.</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> <code>threshold</code> <code>float</code> <p>The threshold value for filtering (default is 1.0E4).</p> <code>10000.0</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determines which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determined which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> <code>axis</code> <code>int</code> <p>The axis along which to apply the patching (default is 1).</p> <code>1</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>keys</code> <code>list of str</code> <p>The list of keys to purge.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>shot_range</code> <code>list</code> <p>The range of shots to consider (default is [0, None]).</p> <code>[0, None]</code> <code>rois</code> <code>list of lists</code> <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> <code>[[0, None]]</code> <code>reduction_function</code> <code>function</code> <p>The function to apply for reduction (default is np.sum).</p> <code>sum</code> <code>purge</code> <code>bool</code> <p>Whether to purge the original detector data after reduction (default is True).</p> <code>True</code> <code>combine</code> <code>bool</code> <p>Whether to combine ROIs (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the data within each bin (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to separate.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>bins</code> <code>array - like</code> <p>The bins to use for time binning.</p> required <code>lxt_key</code> <code>str</code> <p>The key for the laser time delay data (default is 'lxt_ttc').</p> <code>'lxt_ttc'</code> <code>fast_delay_key</code> <code>str</code> <p>The key for the fast delay data (default is 'encoder').</p> <code>'encoder'</code> <code>tt_correction_key</code> <code>str</code> <p>The key for the time tool correction data (default is 'time_tool_correction').</p> <code>'time_tool_correction'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to combine.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>ccm_bins_key</code> <code>str</code> <p>The key corresponding to the CCM bins.</p> required <code>ccm_key</code> <code>str</code> <p>The key corresponding to the CCM data (default is 'ccm').</p> <code>'ccm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>energies</code> <code>array - like</code> <p>Array of energy values to be used for creating CCM bins.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> <code>not_ccm</code> <code>bool</code> <p>Whether to indicate that CCM is not being used (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>threshold</code> <code>int</code> <p>The minimum number of shots required to keep a CCM value (default is 120).</p> <code>120</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>float</code> <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> required <code>R</code> <code>float</code> <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> required <code>pixel_array</code> <code>array - like</code> <p>Array of pixels to determine the energy of.</p> required <code>d</code> <code>float</code> <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> <code>0.895</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>pixel_range</code> <code>list of int</code> <p>The pixel range to sum over for normalization (default is [300, 550]).</p> <code>[300, 550]</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data within the run object.</p> required <code>scanvar_key</code> <code>str</code> <p>The key corresponding to the scan variable indices.</p> required <code>scanvar_bins_key</code> <code>str</code> <p>The key corresponding to the scan variable bins.</p> required <p>Returns:</p> Type Description <code>None</code> <p>The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p> <p>Parameters:</p> Name Type Description Default <code>lcls_run</code> <code>str</code> <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> required <code>hutch</code> <code>str</code> <p>Hutch name. Example: xcs</p> required <code>experiment_id</code> <code>str</code> <p>Experiment identifier. Example: xcsl1004021</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p> <p>Returns:</p> Type Description <code>str</code> <p>The directory of the experiment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run","title":"<code>spectroscopy_run</code>","text":"<p>A class to represent a run within a spectroscopy experiment. Not an LCLS run.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_run:\n    \"\"\"\n    A class to represent a run within a spectroscopy experiment. Not an LCLS run. \n    \"\"\"\n    def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n        \"\"\"\n        Initializes a spectroscopy run instance.\n\n        Parameters\n        ----------\n\n        spec_experiment : spectroscopy_experiment\n            The parent spectroscopy experiment.\n\n        run : int\n            The run number.\n\n        verbose : bool, optional\n            Flag for verbose output used for printing all of the status updates. \n            These statuses are also available in the object itself. Defaults to False.\n\n        end_index : int, optional\n            Index to stop processing data. Defaults to -1.\n\n        start_index : int, optional\n            Index to start processing data. Defaults to 0.\n            These indices are used for batch analysis. \n\n        \"\"\"\n        self.spec_experiment=spec_experiment\n        self.run_number=run\n        self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n        self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n        self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n        self.verbose=verbose\n        self.end_index=end_index\n        self.start_index=start_index\n\n    def get_scan_val(self):\n        \"\"\"\n        Retrieves the scan variable from the HDF5 file of the run. \n        This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.scan_var=fh['scan/scan_variable']\n\n\n    def update_status(self,update):\n        \"\"\"\n        Updates the status log for the run and appends it to the objects status/datetime attibutes.\n        If verbose then it prints it.\n\n        Parameters\n        ----------\n\n        update : str\n            The status update message.\n\n        \"\"\"\n        self.status.append(update)\n        self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        if self.verbose:\n            print(update)\n\n    def get_run_shot_properties(self):\n        \"\"\"\n        Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n            xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n            laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n            self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.simultaneous=np.logical_and(self.xray,self.laser)\n\n        self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n        self.update_status('Obtained shot properties')\n    def set_arbitrary_filter(self,key='arbitrary_filter'):\n        self.verbose=False\n        with h5py.File(self.run_file, 'r') as fh:\n            self.arbitrary_filter = fh[key][self.start_index:self.end_index]\n\n    def load_run_keys(self, keys, friendly_names):\n        \"\"\"\n        Loads specified keys from the run file into memory.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load from the hdf5 file\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n        \"\"\"\n        start=time.time()\n        with h5py.File(self.run_file, 'r') as fh:\n            for key, name in zip(keys, friendly_names):\n\n                try:\n                    setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n                except KeyError as e:\n                    self.update_status('Key does not exist: %s' % e.args[0])\n                except MemoryError:\n                    setattr(self, name, fh[key])\n                    self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n        end=time.time()\n        self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n    def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n        \"\"\"\n        Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n        Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load.\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys.\n\n        transpose : bool, optional\n            Flag to transpose the loaded data. Defaults to False.\n\n        rois : list of lists, optional\n            List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n            Each ROI should be in the form [start_col, end_col].\n\n        combine : bool, optional\n            Whether to combine ROIs into a single mask. Defaults to True.\n\n        \"\"\"\n        start = time.time()\n        fh = h5py.File(self.run_file, 'r')\n\n        for key, name in zip(keys, friendly_names):\n            try:\n                # Load the data from the file for the given key\n                data = fh[key][self.start_index:self.end_index, :, :]\n\n                # Apply one-dimensional ROIs if specified\n                if rois is not None:\n                    if combine:\n                        # Combine multiple ROIs into a single mask\n                        mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                        for roi in rois:\n                            start_col, end_col = roi\n                            mask[start_col:end_col] = True\n                        # Apply the mask to select the ROI from the third dimension\n                        data = data[:, :, mask]\n                    else:\n                        # Handle each ROI separately, storing the results as different attributes\n                        for idx, roi in enumerate(rois):\n                            start_col, end_col = roi\n                            roi_data = data[:, :, start_col:end_col]\n                            setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n                setattr(self, name, data)\n\n                if transpose:\n                    setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n            except KeyError as e:\n                self.update_status(f'Key does not exist: {e.args[0]}')\n            except MemoryError:\n                setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n                self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n        end = time.time()\n        self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n        self.h5 = fh\n\n\n\n    def load_sum_run_scattering(self,key,low=20,high=80):\n        \"\"\"\n        Sums the scattering data across the specified range.\n\n        Parameters\n        ----------\n\n        key : str\n            The key to sum the scattering data from.\n\n        low : int\n            Low index for summing\n\n        high: int \n            high index for summing\n            These indices should be chosen over the water ring or some scattering of interest.\n\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n\n    def close_h5(self):\n        \"\"\"\n        Closes the HDF5 file handle.\n        Again, avoiding memory issues.\n        \"\"\"\n        self.h5.close()\n        del self.h5\n\n    def purge_all_keys(self,keys_to_keep):\n        \"\"\"\n        Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n        Parameters\n        ----------\n\n        keys_to_keep : list\n            List of keys to retain.\n\n        \"\"\"\n\n        new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n        self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.__init__","title":"<code>__init__(spec_experiment, run, verbose=False, end_index=-1, start_index=0)</code>","text":"<p>Initializes a spectroscopy run instance.</p> <p>Parameters:</p> Name Type Description Default <code>spec_experiment</code> <code>spectroscopy_experiment</code> <p>The parent spectroscopy experiment.</p> required <code>run</code> <code>int</code> <p>The run number.</p> required <code>verbose</code> <code>bool</code> <p>Flag for verbose output used for printing all of the status updates.  These statuses are also available in the object itself. Defaults to False.</p> <code>False</code> <code>end_index</code> <code>int</code> <p>Index to stop processing data. Defaults to -1.</p> <code>-1</code> <code>start_index</code> <code>int</code> <p>Index to start processing data. Defaults to 0. These indices are used for batch analysis.</p> <code>0</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n    \"\"\"\n    Initializes a spectroscopy run instance.\n\n    Parameters\n    ----------\n\n    spec_experiment : spectroscopy_experiment\n        The parent spectroscopy experiment.\n\n    run : int\n        The run number.\n\n    verbose : bool, optional\n        Flag for verbose output used for printing all of the status updates. \n        These statuses are also available in the object itself. Defaults to False.\n\n    end_index : int, optional\n        Index to stop processing data. Defaults to -1.\n\n    start_index : int, optional\n        Index to start processing data. Defaults to 0.\n        These indices are used for batch analysis. \n\n    \"\"\"\n    self.spec_experiment=spec_experiment\n    self.run_number=run\n    self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n    self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n    self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n    self.verbose=verbose\n    self.end_index=end_index\n    self.start_index=start_index\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.close_h5","title":"<code>close_h5()</code>","text":"<p>Closes the HDF5 file handle. Again, avoiding memory issues.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def close_h5(self):\n    \"\"\"\n    Closes the HDF5 file handle.\n    Again, avoiding memory issues.\n    \"\"\"\n    self.h5.close()\n    del self.h5\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.get_run_shot_properties","title":"<code>get_run_shot_properties()</code>","text":"<p>Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_run_shot_properties(self):\n    \"\"\"\n    Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n        xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n        laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n        self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.simultaneous=np.logical_and(self.xray,self.laser)\n\n    self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n    self.update_status('Obtained shot properties')\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.get_scan_val","title":"<code>get_scan_val()</code>","text":"<p>Retrieves the scan variable from the HDF5 file of the run.  This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_scan_val(self):\n    \"\"\"\n    Retrieves the scan variable from the HDF5 file of the run. \n    This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.scan_var=fh['scan/scan_variable']\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_key_delayed","title":"<code>load_run_key_delayed(keys, friendly_names, transpose=False, rois=None, combine=True)</code>","text":"<p>Loads specified keys from the run file into memory without immediate conversion to numpy arrays.  Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list</code> <p>List of keys to load.</p> required <code>friendly_names</code> <code>list</code> <p>Corresponding list of friendly names for the keys.</p> required <code>transpose</code> <code>bool</code> <p>Flag to transpose the loaded data. Defaults to False.</p> <code>False</code> <code>rois</code> <code>list of lists</code> <p>List of ROIs (regions of interest) as pixel ranges along one dimension (default is None). Each ROI should be in the form [start_col, end_col].</p> <code>None</code> <code>combine</code> <code>bool</code> <p>Whether to combine ROIs into a single mask. Defaults to True.</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n    \"\"\"\n    Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n    Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load.\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys.\n\n    transpose : bool, optional\n        Flag to transpose the loaded data. Defaults to False.\n\n    rois : list of lists, optional\n        List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n        Each ROI should be in the form [start_col, end_col].\n\n    combine : bool, optional\n        Whether to combine ROIs into a single mask. Defaults to True.\n\n    \"\"\"\n    start = time.time()\n    fh = h5py.File(self.run_file, 'r')\n\n    for key, name in zip(keys, friendly_names):\n        try:\n            # Load the data from the file for the given key\n            data = fh[key][self.start_index:self.end_index, :, :]\n\n            # Apply one-dimensional ROIs if specified\n            if rois is not None:\n                if combine:\n                    # Combine multiple ROIs into a single mask\n                    mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                    for roi in rois:\n                        start_col, end_col = roi\n                        mask[start_col:end_col] = True\n                    # Apply the mask to select the ROI from the third dimension\n                    data = data[:, :, mask]\n                else:\n                    # Handle each ROI separately, storing the results as different attributes\n                    for idx, roi in enumerate(rois):\n                        start_col, end_col = roi\n                        roi_data = data[:, :, start_col:end_col]\n                        setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n            setattr(self, name, data)\n\n            if transpose:\n                setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n        except KeyError as e:\n            self.update_status(f'Key does not exist: {e.args[0]}')\n        except MemoryError:\n            setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n            self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n    end = time.time()\n    self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n    self.h5 = fh\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_run_keys","title":"<code>load_run_keys(keys, friendly_names)</code>","text":"<p>Loads specified keys from the run file into memory.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list</code> <p>List of keys to load from the hdf5 file</p> required <code>friendly_names</code> <code>list</code> <p>Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_keys(self, keys, friendly_names):\n    \"\"\"\n    Loads specified keys from the run file into memory.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load from the hdf5 file\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n    \"\"\"\n    start=time.time()\n    with h5py.File(self.run_file, 'r') as fh:\n        for key, name in zip(keys, friendly_names):\n\n            try:\n                setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n            except KeyError as e:\n                self.update_status('Key does not exist: %s' % e.args[0])\n            except MemoryError:\n                setattr(self, name, fh[key])\n                self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n    end=time.time()\n    self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.load_sum_run_scattering","title":"<code>load_sum_run_scattering(key, low=20, high=80)</code>","text":"<p>Sums the scattering data across the specified range.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to sum the scattering data from.</p> required <code>low</code> <code>int</code> <p>Low index for summing</p> <code>20</code> <code>high</code> <p>high index for summing These indices should be chosen over the water ring or some scattering of interest.</p> <code>80</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_sum_run_scattering(self,key,low=20,high=80):\n    \"\"\"\n    Sums the scattering data across the specified range.\n\n    Parameters\n    ----------\n\n    key : str\n        The key to sum the scattering data from.\n\n    low : int\n        Low index for summing\n\n    high: int \n        high index for summing\n        These indices should be chosen over the water ring or some scattering of interest.\n\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.purge_all_keys","title":"<code>purge_all_keys(keys_to_keep)</code>","text":"<p>Purges all keys from the object except those specified. Again avoid OOM in the analyis object.</p> <p>Parameters:</p> Name Type Description Default <code>keys_to_keep</code> <code>list</code> <p>List of keys to retain.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_all_keys(self,keys_to_keep):\n    \"\"\"\n    Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n    Parameters\n    ----------\n\n    keys_to_keep : list\n        List of keys to retain.\n\n    \"\"\"\n\n    new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n    self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Analysis.html#XSpect.XSpect_Analysis.spectroscopy_run.update_status","title":"<code>update_status(update)</code>","text":"<p>Updates the status log for the run and appends it to the objects status/datetime attibutes. If verbose then it prints it.</p> <p>Parameters:</p> Name Type Description Default <code>update</code> <code>str</code> <p>The status update message.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def update_status(self,update):\n    \"\"\"\n    Updates the status log for the run and appends it to the objects status/datetime attibutes.\n    If verbose then it prints it.\n\n    Parameters\n    ----------\n\n    update : str\n        The status update message.\n\n    \"\"\"\n    self.status.append(update)\n    self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n    if self.verbose:\n        print(update)\n</code></pre>"},{"location":"XSpect_Controller.html","title":"XSpect Controller","text":""},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>key</code> <code>str</code> <p>The key for which unique values are to be binned.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>adu_threshold</code> <code>float or list of float</code> <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p> <code>3.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask.</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> <code>threshold</code> <code>float</code> <p>The threshold value for filtering (default is 1.0E4).</p> <code>10000.0</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determines which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determined which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> <code>axis</code> <code>int</code> <p>The axis along which to apply the patching (default is 1).</p> <code>1</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>keys</code> <code>list of str</code> <p>The list of keys to purge.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>shot_range</code> <code>list</code> <p>The range of shots to consider (default is [0, None]).</p> <code>[0, None]</code> <code>rois</code> <code>list of lists</code> <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> <code>[[0, None]]</code> <code>reduction_function</code> <code>function</code> <p>The function to apply for reduction (default is np.sum).</p> <code>sum</code> <code>purge</code> <code>bool</code> <p>Whether to purge the original detector data after reduction (default is True).</p> <code>True</code> <code>combine</code> <code>bool</code> <p>Whether to combine ROIs (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the data within each bin (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to separate.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>bins</code> <code>array - like</code> <p>The bins to use for time binning.</p> required <code>lxt_key</code> <code>str</code> <p>The key for the laser time delay data (default is 'lxt_ttc').</p> <code>'lxt_ttc'</code> <code>fast_delay_key</code> <code>str</code> <p>The key for the fast delay data (default is 'encoder').</p> <code>'encoder'</code> <code>tt_correction_key</code> <code>str</code> <p>The key for the time tool correction data (default is 'time_tool_correction').</p> <code>'time_tool_correction'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to combine.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>ccm_bins_key</code> <code>str</code> <p>The key corresponding to the CCM bins.</p> required <code>ccm_key</code> <code>str</code> <p>The key corresponding to the CCM data (default is 'ccm').</p> <code>'ccm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>energies</code> <code>array - like</code> <p>Array of energy values to be used for creating CCM bins.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> <code>not_ccm</code> <code>bool</code> <p>Whether to indicate that CCM is not being used (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>threshold</code> <code>int</code> <p>The minimum number of shots required to keep a CCM value (default is 120).</p> <code>120</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>float</code> <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> required <code>R</code> <code>float</code> <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> required <code>pixel_array</code> <code>array - like</code> <p>Array of pixels to determine the energy of.</p> required <code>d</code> <code>float</code> <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> <code>0.895</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>pixel_range</code> <code>list of int</code> <p>The pixel range to sum over for normalization (default is [300, 550]).</p> <code>[300, 550]</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data within the run object.</p> required <code>scanvar_key</code> <code>str</code> <p>The key corresponding to the scan variable indices.</p> required <code>scanvar_bins_key</code> <code>str</code> <p>The key corresponding to the scan variable bins.</p> required <p>Returns:</p> Type Description <code>None</code> <p>The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p> <p>Parameters:</p> Name Type Description Default <code>lcls_run</code> <code>str</code> <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> required <code>hutch</code> <code>str</code> <p>Hutch name. Example: xcs</p> required <code>experiment_id</code> <code>str</code> <p>Experiment identifier. Example: xcsl1004021</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p> <p>Returns:</p> Type Description <code>str</code> <p>The directory of the experiment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Controller.html#XSpect.XSpect_Controller.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Diagnostics.html","title":"XSpect Diagnostics","text":""},{"location":"XSpect_PostProcessing.html","title":"XSpect PostProcessing","text":""},{"location":"XSpect_Visualization.html","title":"XSpect Visualization","text":""},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis","title":"<code>SpectroscopyAnalysis</code>","text":"<p>A class to perform analysis on spectroscopy data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class SpectroscopyAnalysis:\n    \"\"\"\n    A class to perform analysis on spectroscopy data.\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def bin_uniques(self,run,key):\n        \"\"\"\n        Bins unique values for a given key within a run.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        key : str\n            The key for which unique values are to be binned.\n\n        \"\"\"\n        vals = getattr(run,key)\n        bins = np.unique(vals)\n        addon = (bins[-1] - bins[-2])/2 # add on energy \n        bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n        bins_center = np.empty_like(bins2)\n        for ii in np.arange(bins.shape[0]):\n            if ii == 0:\n                bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n            else:\n                bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n        bins_center[-1] = bins2[-1]\n\n        setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n        setattr(run,'scanvar_bins',bins_center)\n\n    def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n        \"\"\"\n        Filters shots based on a given threshold.\n        For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm'). \n\n        threshold : float, optional\n            The threshold value for filtering (default is 1.0E4).\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        nan_mask = np.isnan(filter_mask)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n    def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n        \"\"\"\n        A specific filtering implementation for Nans due to various DAQ issues. \n        Filters out shots with NaN values in the specified filter.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        shot_mask_key : str\n            The key corresponding to the shot mask.\n\n        filter_key : str, optional\n            The key corresponding to the filter data (default is 'ipm').\n\n        \"\"\"\n        shot_mask=getattr(run,shot_mask_key)\n        count_before=np.sum(shot_mask)\n        filter_mask=getattr(run,filter_key)\n        filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n        count_after=np.sum(filtered_shot_mask)\n        setattr(run,shot_mask_key,filtered_shot_mask)\n        run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n\n\n    def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n        \"\"\"\n        Filters is a misnomer compared to the other filter functions. \n        This sets detector pixel values below a threshold to 0.\n        Specifically, to remove 0-photon noise from detectors. \n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector : str\n            The key corresponding to the detector data.\n\n        adu_threshold : float or list of float, optional\n            The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n        Returns\n        -------\n\n        np.ndarray\n            The filtered detector data.\n\n        \"\"\"\n        detector_images=getattr(run,detector)\n        if isinstance(adu_threshold,list):\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n            detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n            run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n        else:\n            detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n            run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n        setattr(run,detector,detector_images_adu)\n\n        return detector_images_adu\n\n    def purge_keys(self,run,keys):\n        \"\"\"\n        Purges specific keys from the run to save memory.\n        This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n        To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        keys : list of str\n            The list of keys to purge.\n\n        \"\"\"\n        for detector_key in keys:\n            setattr(run, detector_key, None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_shots(self, run, detector_key,reduction_function=np.sum,  purge=True,new_key=False):\n        detector = getattr(run, detector_key)\n        reduced_data=reduction_function(detector,axis=0)\n        run.update_status(f\"Reduced detector by shots: {detector_key} with number of shots: {np.shape(detector)}\")\n        if new_key:\n            target_key=f\"{detector_key}_summed\"\n        else:\n            target_key=detector_key\n        setattr(run, target_key, reduced_data)\n        if purge:\n            setattr(run, detector_key,None)\n            run.update_status(f\"Purged key to save room: {detector_key}\")\n\n    def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n        \"\"\"\n        Reduces the spatial dimension of detector data based on specified ROIs.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        shot_range : list, optional\n            The range of shots to consider (default is [0, None]).\n\n        rois : list of lists, optional\n            The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n        reduction_function : function, optional\n            The function to apply for reduction (default is np.sum).\n\n        purge : bool, optional\n            Whether to purge the original detector data after reduction (default is True).\n\n        combine : bool, optional\n            Whether to combine ROIs (default is True).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if combine:\n\n            roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n            mask = np.zeros(detector.shape[-1], dtype=bool)\n            for roi in rois:\n                mask[roi[0]:roi[1]] = True\n            if detector.ndim==3:\n                masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n            elif detector.ndim==2:\n                masked_data = detector[:, mask]\n            elif detector.ndim==1:\n                masked_data = detector[mask]\n            reduced_data = reduction_function(masked_data, axis=-1)\n            roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n            run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n            setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n        else:\n            for idx, roi in enumerate(rois):\n                data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n                reduced_data = reduction_function(data_chunk, **kwargs)\n            if roi[1] is None:\n                roi[1] = detector.shape[1] - 1\n                run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n                setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n        if purge:\n            #pass\n            setattr(run, detector_key,None)\n            #delattr(run, detector_key)\n            #del run.detector_key\n            run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n\n    def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n        \"\"\"\n        Bins data in time based on specified bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        bins : array-like\n            The bins to use for time binning.\n\n        lxt_key : str, optional\n            The key for the laser time delay data (default is 'lxt_ttc').\n\n        fast_delay_key : str, optional\n            The key for the fast delay data (default is 'encoder').\n\n        tt_correction_key : str, optional\n            The key for the time tool correction data (default is 'time_tool_correction').\n\n        \"\"\"\n        if lxt_key==None:\n            run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        else:\n            run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n        run.time_bins=bins\n        run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n        run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n    def union_shots(self, run, detector_key, filter_keys,new_key=True):\n        \"\"\"\n        Combines shots across multiple filters into a single array. \n        So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n        means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to combine.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        if isinstance(filter_keys, list):\n            mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        if new_key:\n            target_key=detector_key + '_' + '_'.join(filter_keys)\n        else:\n            target_key=detector_key\n        setattr(run, target_key, filtered_detector)\n        run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n\n    def separate_shots(self, run, detector_key, filter_keys):\n        \"\"\"\n        Separates shots into different datasets based on filters.\n        separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n        If you wanted the inverse you would switch the order of the filter_keys.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        filter_keys : list of str\n            The list of filter keys to separate.\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        if isinstance(filter_keys, list):\n            mask1 = getattr(run, filter_keys[0])\n            mask2 = np.logical_not(getattr(run, filter_keys[1]))\n            mask = np.logical_and(mask1, mask2)\n        else:\n            mask = getattr(run, filter_keys)\n        filtered_detector = detector[mask]\n        setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n        run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n        \"\"\"\n        Reduces the temporal dimension of detector data based on timing bins.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the data within each bin (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        indices = getattr(run, timing_bin_key_indices)\n        expected_length = len(run.time_bins)+1\n        if len(detector.shape) &lt; 2:\n            reduced_array = np.zeros((expected_length))\n        elif len(detector.shape) &lt; 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1]))\n        elif len(detector.shape) == 3:\n            reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n        counts = np.bincount(indices)\n        if average:\n            np.add.at(reduced_array, indices, detector)\n            reduced_array /= counts[:, None]\n        else:\n            np.add.at(reduced_array, indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n    def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n        \"\"\"\n        Patches multiple pixels in detector data.\n\n        Parameters\n        ----------\n\n        run : spectroscopy_run\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n        axis : int, optional\n            The axis along which to apply the patching (default is 1).\n\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n\n\n    def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n\n        Parameters\n        ----------\n\n        data : array_like\n            Array of shots\n\n        pixel : integer\n            Pixel point to be patched\n\n        mode : string\n            Determines which mode to use for patching the pixel. Averaging works well.\n\n        patch_range : integer\n            Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n\n        Returns\n        -------\n\n        float\n            The original data with the new patch values.\n\n        \"\"\"\n        data = getattr(run, detector_key)\n\n        def get_neighbor_values(data, pixel, patch_range, axis):\n            axis_slice = [slice(None)] * data.ndim\n            start_index = max(pixel - patch_range, 0)\n            end_index = min(pixel + patch_range + 1, data.shape[axis])\n            axis_slice[axis] = slice(start_index, end_index)\n            return data[tuple(axis_slice)]\n\n        def patch_value_average(data, pixel, patch_range, axis):\n            neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n            new_val = np.mean(neighbor_values, axis=0)\n            return new_val\n\n        def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[patch_range:-patch_range] = 0.001\n\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]): \n                ys = neighbor_values[:, idx]\n                coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n                new_vals.append(np.polyval(coeffs, pixel))\n            return np.array(new_vals)\n\n        def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n            neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n            neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n            new_vals = []\n            for idx in range(neighbor_values.shape[1]):\n                ys = neighbor_values[:, idx]\n                interp_func = interp1d(patch_x, ys, kind='quadratic')\n                new_vals.append(interp_func(pixel))\n            return np.array(new_vals)\n\n        if mode == 'average':\n            new_val = patch_value_average(data, pixel, patch_range, axis)\n        elif mode == 'polynomial':\n            new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n        elif mode == 'interpolate':\n            new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n        else:\n            raise ValueError(f\"Unsupported mode: {mode}\")\n\n        patch_slice = [slice(None)] * data.ndim\n        patch_slice[axis] = pixel\n        data[tuple(patch_slice)] = new_val\n\n        setattr(run, detector_key, data)\n        run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n\n    def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        Patches multiple pixels in 1D detector data.\n\n        Parameters\n        ----------\n        run : spectroscopy_run\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        mode : str, optional\n            The mode of patching ('average', 'polynomial', or 'interpolate').\n        patch_range : int, optional\n            The range around the pixel to use for patching (default is 4).\n        deg : int, optional\n            The degree of the polynomial for polynomial patching (default is 1).\n        poly_range : int, optional\n            The range of pixels to use for polynomial or interpolation patching (default is 6).\n        \"\"\"\n        for pixel in self.pixels_to_patch:\n            self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n    def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n        \"\"\"\n        EPIX detector pixel patching.\n        TODO: extend to patch regions instead of per pixel.\n        Parameters\n        ----------\n        data : array_like\n            Array of shots\n        pixel : integer\n            Pixel point to be patched\n        mode : string\n            Determined which mode to use for patching the pixel. Averaging works well.\n        patch_range : integer\n            pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n        deg : integer\n            Degree of polynomial if polynomial patching is used.\n        poly_range : integer\n            Number of pixels to include in the polynomial or interpolation fitting\n        Returns\n        -------\n        float\n            The original data with the new patch values.\n        \"\"\"\n        data = getattr(run, detector_key)\n        if mode == 'average':\n            neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n            data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n        elif mode == 'polynomial':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            patch_range_weights = np.ones(len(patch_x))\n            patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n            coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                                w=patch_range_weights)\n            data[pixel, :] = np.polyval(coeffs, pixel)\n        elif mode == 'interpolate':\n            patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n            interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                              kind='quadratic')\n            data[pixel, :] = interp(pixel)\n        setattr(run,detector_key,data)\n        run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.bin_uniques","title":"<code>bin_uniques(run, key)</code>","text":"<p>Bins unique values for a given key within a run.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>key</code> <code>str</code> <p>The key for which unique values are to be binned.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def bin_uniques(self,run,key):\n    \"\"\"\n    Bins unique values for a given key within a run.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    key : str\n        The key for which unique values are to be binned.\n\n    \"\"\"\n    vals = getattr(run,key)\n    bins = np.unique(vals)\n    addon = (bins[-1] - bins[-2])/2 # add on energy \n    bins2 = np.append(bins,bins[-1]+addon) # elist2 will be elist with dummy value at end\n    bins_center = np.empty_like(bins2)\n    for ii in np.arange(bins.shape[0]):\n        if ii == 0:\n            bins_center[ii] = bins2[ii] - (bins2[ii+1] - bins2[ii])/2\n        else:\n            bins_center[ii] = bins2[ii] - (bins2[ii] - bins2[ii-1])/2\n    bins_center[-1] = bins2[-1]\n\n    setattr(run,'scanvar_indices',np.digitize(vals,bins_center))\n    setattr(run,'scanvar_bins',bins_center)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_detector_adu","title":"<code>filter_detector_adu(run, detector, adu_threshold=3.0)</code>","text":"<p>Filters is a misnomer compared to the other filter functions.  This sets detector pixel values below a threshold to 0. Specifically, to remove 0-photon noise from detectors. </p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>adu_threshold</code> <code>float or list of float</code> <p>The ADU threshold for filtering. Can be a single value or a range (default is 3.0).</p> <code>3.0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>The filtered detector data.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_detector_adu(self,run,detector,adu_threshold=3.0):\n    \"\"\"\n    Filters is a misnomer compared to the other filter functions. \n    This sets detector pixel values below a threshold to 0.\n    Specifically, to remove 0-photon noise from detectors. \n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector : str\n        The key corresponding to the detector data.\n\n    adu_threshold : float or list of float, optional\n        The ADU threshold for filtering. Can be a single value or a range (default is 3.0).\n\n    Returns\n    -------\n\n    np.ndarray\n        The filtered detector data.\n\n    \"\"\"\n    detector_images=getattr(run,detector)\n    if isinstance(adu_threshold,list):\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold[0])\n        detector_images_adu = detector_images_adu * (detector_images_adu &lt; adu_threshold[1])\n        run.update_status('Key: %s has been adu filtered by thresholds: %f,%f' % (detector,adu_threshold[0],adu_threshold[1]))\n    else:\n        detector_images_adu = detector_images * (detector_images &gt; adu_threshold)\n        run.update_status('Key: %s has been adu filtered by threshold: %f' % (detector,adu_threshold))\n\n    setattr(run,detector,detector_images_adu)\n\n    return detector_images_adu\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_nan","title":"<code>filter_nan(run, shot_mask_key, filter_key='ipm')</code>","text":"<p>A specific filtering implementation for Nans due to various DAQ issues.  Filters out shots with NaN values in the specified filter.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask.</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_nan(self, run,shot_mask_key, filter_key='ipm'):\n    \"\"\"\n    A specific filtering implementation for Nans due to various DAQ issues. \n    Filters out shots with NaN values in the specified filter.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask.\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm').\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.filter_shots","title":"<code>filter_shots(run, shot_mask_key, filter_key='ipm', threshold=10000.0)</code>","text":"<p>Filters shots based on a given threshold. For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>shot_mask_key</code> <code>str</code> <p>The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots</p> required <code>filter_key</code> <code>str</code> <p>The key corresponding to the filter data (default is 'ipm').</p> <code>'ipm'</code> <code>threshold</code> <code>float</code> <p>The threshold value for filtering (default is 1.0E4).</p> <code>10000.0</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def filter_shots(self, run,shot_mask_key, filter_key='ipm', threshold=1.0E4):\n    \"\"\"\n    Filters shots based on a given threshold.\n    For example, if we filter: xray,ipm,1E4 then X-ray shots will be filtered out if the ipm is below 1E4.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    shot_mask_key : str\n        The key corresponding to the shot mask. An example being [xray,simultaneous,laser] for all x-ray shots\n\n    filter_key : str, optional\n        The key corresponding to the filter data (default is 'ipm'). \n\n    threshold : float, optional\n        The threshold value for filtering (default is 1.0E4).\n\n    \"\"\"\n    shot_mask=getattr(run,shot_mask_key)\n    count_before=np.sum(shot_mask)\n    filter_mask=getattr(run,filter_key)\n    nan_mask = np.isnan(filter_mask)\n    filtered_shot_mask=shot_mask * (filter_mask&gt;threshold)* (~nan_mask)\n    count_after=np.sum(filtered_shot_mask)\n    setattr(run,shot_mask_key,filtered_shot_mask)\n    run.update_status('Mask: %s has been filtered on %s by minimum threshold: %0.3f\\nShots removed: %d' % (shot_mask_key,filter_key,threshold,count_before-count_after))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel","title":"<code>patch_pixel(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determines which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6, axis=1):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n\n    Parameters\n    ----------\n\n    data : array_like\n        Array of shots\n\n    pixel : integer\n        Pixel point to be patched\n\n    mode : string\n        Determines which mode to use for patching the pixel. Averaging works well.\n\n    patch_range : integer\n        Pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n\n    Returns\n    -------\n\n    float\n        The original data with the new patch values.\n\n    \"\"\"\n    data = getattr(run, detector_key)\n\n    def get_neighbor_values(data, pixel, patch_range, axis):\n        axis_slice = [slice(None)] * data.ndim\n        start_index = max(pixel - patch_range, 0)\n        end_index = min(pixel + patch_range + 1, data.shape[axis])\n        axis_slice[axis] = slice(start_index, end_index)\n        return data[tuple(axis_slice)]\n\n    def patch_value_average(data, pixel, patch_range, axis):\n        neighbor_values = get_neighbor_values(data, pixel, patch_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n        new_val = np.mean(neighbor_values, axis=0)\n        return new_val\n\n    def patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[patch_range:-patch_range] = 0.001\n\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]): \n            ys = neighbor_values[:, idx]\n            coeffs = np.polyfit(patch_x, ys, deg, w=patch_range_weights)\n            new_vals.append(np.polyval(coeffs, pixel))\n        return np.array(new_vals)\n\n    def patch_value_interpolate(data, pixel, patch_range, poly_range, axis):\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1)\n        neighbor_values = get_neighbor_values(data, pixel, patch_range + poly_range, axis)\n        neighbor_values = np.moveaxis(neighbor_values, axis, 0)\n\n        new_vals = []\n        for idx in range(neighbor_values.shape[1]):\n            ys = neighbor_values[:, idx]\n            interp_func = interp1d(patch_x, ys, kind='quadratic')\n            new_vals.append(interp_func(pixel))\n        return np.array(new_vals)\n\n    if mode == 'average':\n        new_val = patch_value_average(data, pixel, patch_range, axis)\n    elif mode == 'polynomial':\n        new_val = patch_value_polynomial(data, pixel, patch_range, poly_range, deg, axis)\n    elif mode == 'interpolate':\n        new_val = patch_value_interpolate(data, pixel, patch_range, poly_range, axis)\n    else:\n        raise ValueError(f\"Unsupported mode: {mode}\")\n\n    patch_slice = [slice(None)] * data.ndim\n    patch_slice[axis] = pixel\n    data[tuple(patch_slice)] = new_val\n\n    setattr(run, detector_key, data)\n    run.update_status(f\"Detector {detector_key} pixel {pixel} patched. Old value.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixel_1d","title":"<code>patch_pixel_1d(run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>EPIX detector pixel patching. TODO: extend to patch regions instead of per pixel.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array_like</code> <p>Array of shots</p> required <code>pixel</code> <code>integer</code> <p>Pixel point to be patched</p> required <code>mode</code> <code>string</code> <p>Determined which mode to use for patching the pixel. Averaging works well.</p> <code>'average'</code> <code>patch_range</code> <code>integer</code> <p>pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.</p> <code>4</code> <code>deg</code> <code>integer</code> <p>Degree of polynomial if polynomial patching is used.</p> <code>1</code> <code>poly_range</code> <code>integer</code> <p>Number of pixels to include in the polynomial or interpolation fitting</p> <code>6</code> <p>Returns:</p> Type Description <code>float</code> <p>The original data with the new patch values.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixel_1d(self, run, detector_key, pixel, mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    EPIX detector pixel patching.\n    TODO: extend to patch regions instead of per pixel.\n    Parameters\n    ----------\n    data : array_like\n        Array of shots\n    pixel : integer\n        Pixel point to be patched\n    mode : string\n        Determined which mode to use for patching the pixel. Averaging works well.\n    patch_range : integer\n        pixels away from the pixel to be patched to be used for patching. Needed if multiple pixels in a row are an issue.\n    deg : integer\n        Degree of polynomial if polynomial patching is used.\n    poly_range : integer\n        Number of pixels to include in the polynomial or interpolation fitting\n    Returns\n    -------\n    float\n        The original data with the new patch values.\n    \"\"\"\n    data = getattr(run, detector_key)\n    if mode == 'average':\n        neighbor_values = data[:, pixel - patch_range:pixel + patch_range + 1]\n        data[:, pixel] = np.sum(neighbor_values, axis=1) / neighbor_values.shape[1]\n    elif mode == 'polynomial':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        patch_range_weights = np.ones(len(patch_x))\n        patch_range_weights[pixel - patch_range - poly_range:pixel + patch_range + poly_range] = 0.001\n        coeffs = np.polyfit(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1], deg,\n                            w=patch_range_weights)\n        data[pixel, :] = np.polyval(coeffs, pixel)\n    elif mode == 'interpolate':\n        patch_x = np.arange(pixel - patch_range - poly_range, pixel + patch_range + poly_range + 1, 1)\n        interp = interp1d(patch_x, data[pixel - patch_range - poly_range:pixel + patch_range + poly_range + 1, :],\n                          kind='quadratic')\n        data[pixel, :] = interp(pixel)\n    setattr(run,detector_key,data)\n    run.update_status('Detector %s pixel %d patched in mode %s'%(detector_key, pixel,mode ))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels","title":"<code>patch_pixels(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6, axis=1)</code>","text":"<p>Patches multiple pixels in detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> <code>axis</code> <code>int</code> <p>The axis along which to apply the patching (default is 1).</p> <code>1</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6,axis=1):\n    \"\"\"\n    Patches multiple pixels in detector data.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n\n    axis : int, optional\n        The axis along which to apply the patching (default is 1).\n\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel(run,detector_key,pixel,mode,patch_range,deg,poly_range,axis=axis)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.patch_pixels_1d","title":"<code>patch_pixels_1d(run, detector_key, mode='average', patch_range=4, deg=1, poly_range=6)</code>","text":"<p>Patches multiple pixels in 1D detector data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>mode</code> <code>str</code> <p>The mode of patching ('average', 'polynomial', or 'interpolate').</p> <code>'average'</code> <code>patch_range</code> <code>int</code> <p>The range around the pixel to use for patching (default is 4).</p> <code>4</code> <code>deg</code> <code>int</code> <p>The degree of the polynomial for polynomial patching (default is 1).</p> <code>1</code> <code>poly_range</code> <code>int</code> <p>The range of pixels to use for polynomial or interpolation patching (default is 6).</p> <code>6</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def patch_pixels_1d(self,run,detector_key,  mode='average', patch_range=4, deg=1, poly_range=6):\n    \"\"\"\n    Patches multiple pixels in 1D detector data.\n\n    Parameters\n    ----------\n    run : spectroscopy_run\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    mode : str, optional\n        The mode of patching ('average', 'polynomial', or 'interpolate').\n    patch_range : int, optional\n        The range around the pixel to use for patching (default is 4).\n    deg : int, optional\n        The degree of the polynomial for polynomial patching (default is 1).\n    poly_range : int, optional\n        The range of pixels to use for polynomial or interpolation patching (default is 6).\n    \"\"\"\n    for pixel in self.pixels_to_patch:\n        self.patch_pixel_1d(run,detector_key,pixel,mode,patch_range,deg,poly_range)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.purge_keys","title":"<code>purge_keys(run, keys)</code>","text":"<p>Purges specific keys from the run to save memory. This is specifically to remove the epix key immediately after processing it from the hdf5 file. To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>keys</code> <code>list of str</code> <p>The list of keys to purge.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_keys(self,run,keys):\n    \"\"\"\n    Purges specific keys from the run to save memory.\n    This is specifically to remove the epix key immediately after processing it from the hdf5 file.\n    To avoid OOM. This is different than the purge all keys method which is used to purge many of the larger analysis steps.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    keys : list of str\n        The list of keys to purge.\n\n    \"\"\"\n    for detector_key in keys:\n        setattr(run, detector_key, None)\n        run.update_status(f\"Purged key to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_spatial","title":"<code>reduce_detector_spatial(run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum, purge=True, combine=True)</code>","text":"<p>Reduces the spatial dimension of detector data based on specified ROIs.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>shot_range</code> <code>list</code> <p>The range of shots to consider (default is [0, None]).</p> <code>[0, None]</code> <code>rois</code> <code>list of lists</code> <p>The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).</p> <code>[[0, None]]</code> <code>reduction_function</code> <code>function</code> <p>The function to apply for reduction (default is np.sum).</p> <code>sum</code> <code>purge</code> <code>bool</code> <p>Whether to purge the original detector data after reduction (default is True).</p> <code>True</code> <code>combine</code> <code>bool</code> <p>Whether to combine ROIs (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_spatial(self, run, detector_key, shot_range=[0, None], rois=[[0, None]], reduction_function=np.sum,  purge=True, combine=True):\n    \"\"\"\n    Reduces the spatial dimension of detector data based on specified ROIs.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    shot_range : list, optional\n        The range of shots to consider (default is [0, None]).\n\n    rois : list of lists, optional\n        The list of ROIs (regions of interest) as pixel ranges (default is [[0, None]]).\n\n    reduction_function : function, optional\n        The function to apply for reduction (default is np.sum).\n\n    purge : bool, optional\n        Whether to purge the original detector data after reduction (default is True).\n\n    combine : bool, optional\n        Whether to combine ROIs (default is True).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if combine:\n\n        roi_combined = [rois[0][0], rois[-1][1]]  # Combined ROI spanning the first and last ROI\n        mask = np.zeros(detector.shape[-1], dtype=bool)\n        for roi in rois:\n            mask[roi[0]:roi[1]] = True\n        if detector.ndim==3:\n            masked_data = detector[shot_range[0]:shot_range[1], :, :][:, :, mask]\n        elif detector.ndim==2:\n            masked_data = detector[:, mask]\n        elif detector.ndim==1:\n            masked_data = detector[mask]\n        reduced_data = reduction_function(masked_data, axis=-1)\n        roi_indices = ', '.join([f\"{roi[0]}-{roi[1]}\" for roi in rois])\n        run.update_status(f\"Spatially reduced detector: {detector_key} with combined ROI indices: {roi_indices}\")\n        setattr(run, f\"{detector_key}_ROI_1\", reduced_data)\n    else:\n        for idx, roi in enumerate(rois):\n            data_chunk = detector[shot_range[0]:shot_range[1], roi[0]:roi[1]]\n            reduced_data = reduction_function(data_chunk, **kwargs)\n        if roi[1] is None:\n            roi[1] = detector.shape[1] - 1\n            run.update_status(f\"Spatially reduced detector: {detector_key} with ROI: {roi[0]}, {roi[1]}\")\n            setattr(run, f\"{detector_key}_ROI_{idx+1}\", reduced_data)\n    if purge:\n        #pass\n        setattr(run, detector_key,None)\n        #delattr(run, detector_key)\n        #del run.detector_key\n        run.update_status(f\"Purged key after spatial reduction to save room: {detector_key}\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduces the temporal dimension of detector data based on timing bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the data within each bin (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices,average=False):\n    \"\"\"\n    Reduces the temporal dimension of detector data based on timing bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the data within each bin (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    indices = getattr(run, timing_bin_key_indices)\n    expected_length = len(run.time_bins)+1\n    if len(detector.shape) &lt; 2:\n        reduced_array = np.zeros((expected_length))\n    elif len(detector.shape) &lt; 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1]))\n    elif len(detector.shape) == 3:\n        reduced_array = np.zeros((expected_length, detector.shape[1], detector.shape[2]))\n\n    counts = np.bincount(indices)\n    if average:\n        np.add.at(reduced_array, indices, detector)\n        reduced_array /= counts[:, None]\n    else:\n        np.add.at(reduced_array, indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s from detector shape: %s to reduced shape: %s'%(detector_key,detector_key+'_time_binned', detector.shape,reduced_array.shape) )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.separate_shots","title":"<code>separate_shots(run, detector_key, filter_keys)</code>","text":"<p>Separates shots into different datasets based on filters. separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser. If you wanted the inverse you would switch the order of the filter_keys.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to separate.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def separate_shots(self, run, detector_key, filter_keys):\n    \"\"\"\n    Separates shots into different datasets based on filters.\n    separate_shots(f,'epix_ROI_1',['xray','laser']) means find me the epix_ROI_1 images in shots that were X-ray but NOT laser.\n    If you wanted the inverse you would switch the order of the filter_keys.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to separate.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    if isinstance(filter_keys, list):\n        mask1 = getattr(run, filter_keys[0])\n        mask2 = np.logical_not(getattr(run, filter_keys[1]))\n        mask = np.logical_and(mask1, mask2)\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    setattr(run, detector_key + '_' +filter_keys[0]+'_not_'+filter_keys[1], filtered_detector)\n    run.update_status('Shots (%d) separated for detector %s on filters: %s and %s into %s'%(np.sum(mask),detector_key,filter_keys[0],filter_keys[1],detector_key + '_' + '_'.join(filter_keys)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.time_binning","title":"<code>time_binning(run, bins, lxt_key='lxt_ttc', fast_delay_key='encoder', tt_correction_key='time_tool_correction')</code>","text":"<p>Bins data in time based on specified bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>bins</code> <code>array - like</code> <p>The bins to use for time binning.</p> required <code>lxt_key</code> <code>str</code> <p>The key for the laser time delay data (default is 'lxt_ttc').</p> <code>'lxt_ttc'</code> <code>fast_delay_key</code> <code>str</code> <p>The key for the fast delay data (default is 'encoder').</p> <code>'encoder'</code> <code>tt_correction_key</code> <code>str</code> <p>The key for the time tool correction data (default is 'time_tool_correction').</p> <code>'time_tool_correction'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def time_binning(self,run,bins,lxt_key='lxt_ttc',fast_delay_key='encoder',tt_correction_key='time_tool_correction'):\n    \"\"\"\n    Bins data in time based on specified bins.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    bins : array-like\n        The bins to use for time binning.\n\n    lxt_key : str, optional\n        The key for the laser time delay data (default is 'lxt_ttc').\n\n    fast_delay_key : str, optional\n        The key for the fast delay data (default is 'encoder').\n\n    tt_correction_key : str, optional\n        The key for the time tool correction data (default is 'time_tool_correction').\n\n    \"\"\"\n    if lxt_key==None:\n        run.delays = 0+ getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    else:\n        run.delays = getattr(run,lxt_key)*1.0e12 + getattr(run,fast_delay_key)  + getattr(run,tt_correction_key)\n    run.time_bins=bins\n    run.timing_bin_indices=np.digitize(run.delays, bins)[:]\n    run.update_status('Generated timing bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyAnalysis.union_shots","title":"<code>union_shots(run, detector_key, filter_keys, new_key=True)</code>","text":"<p>Combines shots across multiple filters into a single array.  So union_shots(f,'timing_bin_indices',['simultaneous','laser']) means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>spectroscopy_run</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>filter_keys</code> <code>list of str</code> <p>The list of filter keys to combine.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def union_shots(self, run, detector_key, filter_keys,new_key=True):\n    \"\"\"\n    Combines shots across multiple filters into a single array. \n    So union_shots(f,'timing_bin_indices',['simultaneous','laser'])\n    means go through the timing_bin_indices and find the ones that correspond to X-rays and laser shots.\n\n    Parameters\n    ----------\n\n    run : spectroscopy_run\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    filter_keys : list of str\n        The list of filter keys to combine.\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    if isinstance(filter_keys, list):\n        mask = np.logical_and.reduce([getattr(run, k) for k in filter_keys])\n    else:\n        mask = getattr(run, filter_keys)\n    filtered_detector = detector[mask]\n    if new_key:\n        target_key=detector_key + '_' + '_'.join(filter_keys)\n    else:\n        target_key=detector_key\n    setattr(run, target_key, filtered_detector)\n    run.update_status('Shots combined for detector %s on filters: %s and %s into %s'%(detector_key, filter_keys[0],filter_keys[1],target_key))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyVisualization","title":"<code>SpectroscopyVisualization</code>","text":"Source code in <code>XSpect/XSpect_Visualization.py</code> <pre><code>class SpectroscopyVisualization:                \n    def __init__(self):\n        pass\n    def plot_2d_spectrum(self,run,detector_key):\n        spectrum= getattr(run, detector_key)\n        vmin, vmax = np.percentile(spectrum, [1,99])\n        fig,ax=plt.subplots(1,1)\n        im=ax.imshow(spectrum, vmin=vmin, vmax=vmax, origin='lower',aspect='auto')\n\n    def plot_2d_difference_spectrum(self,run,detector_keys):\n        spectrum_1= getattr(run, detector_keys[0])\n        spectrum_2= getattr(run, detector_keys[1])\n        spectrum=spectrum_1-spectrum_2\n        vmin, vmax = np.percentile(spectrum, [1,99])\n        fig,ax=plt.subplots(1,1)\n        im=ax.imshow(spectrum, vmin=vmin, vmax=vmax, origin='lower',aspect='auto')\n        run.difference_spectrum=spectrum\n\n    def make_energy_axis(self, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(np.shape(self.summed_xes)[0], dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        self.energy=xaxis[:]\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.SpectroscopyVisualization.make_energy_axis","title":"<code>make_energy_axis(A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>float</code> <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> required <code>R</code> <code>float</code> <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> required <code>pixel_array</code> <code>array - like</code> <p>Array of pixels to determine the energy of.</p> required <code>d</code> <code>float</code> <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> <code>0.895</code> Source code in <code>XSpect/XSpect_Visualization.py</code> <pre><code>def make_energy_axis(self, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(np.shape(self.summed_xes)[0], dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    self.energy=xaxis[:]\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis","title":"<code>XASAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XASAnalysis(SpectroscopyAnalysis):\n    def __init__(self):\n        pass;\n    def trim_ccm(self,run,threshold=120):\n        \"\"\"\n        Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        threshold : int, optional\n            The minimum number of shots required to keep a CCM value (default is 120).\n\n        \"\"\"\n\n        ccm_bins=getattr(run,'ccm_bins',elist_center)\n        ccm_energies=getattr(run,'ccm_energies',elist)\n        counts = np.bincount(bins)\n        trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n        self.make_ccm_axis(run,ccm_energies)\n\n    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n    def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n        \"\"\"\n        Reduce detector data temporally and by CCM bins.\n\n        Parameters\n        ----------\n        run : object\n            The spectroscopy run instance.\n        detector_key : str\n            The key corresponding to the detector data.\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n        average : bool, optional\n            Whether to average the reduced data (default is True).\n        \"\"\"\n        detector = getattr(run, detector_key)\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n        unique_indices =np.column_stack((timing_indices, ccm_indices))\n        np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n        reduced_array = reduced_array[:-1,:]\n        setattr(run, detector_key+'_time_energy_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n\n    def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n        \"\"\"\n        Reduce detector data by CCM bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        ccm_bin_key_indices : str\n            The key corresponding to the CCM bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        not_ccm : bool, optional\n            Whether to indicate that CCM is not being used (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n\n        ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n        if not_ccm:\n            reduced_array = np.zeros(np.max(ccm_indices)+1 )\n        else:\n            reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n        np.add.at(reduced_array, ccm_indices, detector)\n        setattr(run, detector_key+'_energy_binned', reduced_array)\n\n        run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n\n    def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n        \"\"\"\n        Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        timing_bin_key_indices : str\n            The key corresponding to the timing bin indices.\n\n        average : bool, optional\n            Whether to average the reduced data (default is False).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        time_bins=run.time_bins\n        timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n        reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n        np.add.at(reduced_array, timing_indices, detector)\n        setattr(run, detector_key+'_time_binned', reduced_array)\n        run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n\n    def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n        \"\"\"\n        Generate CCM bin indices from CCM data and bins.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        ccm_bins_key : str\n            The key corresponding to the CCM bins.\n\n        ccm_key : str, optional\n            The key corresponding to the CCM data (default is 'ccm').\n\n        \"\"\"\n        ccm=getattr(run,ccm_key)\n        bins=getattr(run,ccm_bins_key)\n        run.ccm_bin_indices=np.digitize(ccm, bins)\n        run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.ccm_binning","title":"<code>ccm_binning(run, ccm_bins_key, ccm_key='ccm')</code>","text":"<p>Generate CCM bin indices from CCM data and bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>ccm_bins_key</code> <code>str</code> <p>The key corresponding to the CCM bins.</p> required <code>ccm_key</code> <code>str</code> <p>The key corresponding to the CCM data (default is 'ccm').</p> <code>'ccm'</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def ccm_binning(self,run,ccm_bins_key,ccm_key='ccm'):\n    \"\"\"\n    Generate CCM bin indices from CCM data and bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    ccm_bins_key : str\n        The key corresponding to the CCM bins.\n\n    ccm_key : str, optional\n        The key corresponding to the CCM data (default is 'ccm').\n\n    \"\"\"\n    ccm=getattr(run,ccm_key)\n    bins=getattr(run,ccm_bins_key)\n    run.ccm_bin_indices=np.digitize(ccm, bins)\n    run.update_status('Generated ccm bins from %f to %f in %d steps.' % (np.min(bins),np.max(bins),len(bins)))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.make_ccm_axis","title":"<code>make_ccm_axis(run, energies)</code>","text":"<p>Generate CCM bins and centers from given energy values.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>energies</code> <code>array - like</code> <p>Array of energy values to be used for creating CCM bins.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>    def make_ccm_axis(self,run,energies):\n        \"\"\"\n        Generate CCM bins and centers from given energy values.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        energies : array-like\n            Array of energy values to be used for creating CCM bins.\n\n        \"\"\"\n        elist=energies\n#         addon = (elist[-1] - elist[-2])/2 # add on energy \n#         elist2 = np.append(elist,elist[-1]+addon) # elist2 will be elist with dummy value at end\n#         elist_center = np.empty_like(elist2)\n#         for ii in np.arange(elist.shape[0]):\n#             if ii == 0:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii+1] - elist2[ii])/2\n#             else:\n#                 elist_center[ii] = elist2[ii] - (elist2[ii] - elist2[ii-1])/2\n#                 elist_center[-1] = elist2[-1]\n        addon = (elist[-1] - elist[-2])/2\n        elist2 = np.append(elist,elist[-1]+addon)\n        elist_center = np.empty_like(elist)\n\n        for ii in np.arange(elist_center.shape[0]):\n            if ii == elist_center.shape[0]:\n                elist_center[ii] = elist[-1]+addon\n            else:\n                elist_center[ii] = elist2[ii+1] - (elist2[ii+1] - elist2[ii])/2    \n\n        setattr(run,'ccm_bins',elist_center)\n        setattr(run,'ccm_energies',elist)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm","title":"<code>reduce_detector_ccm(run, detector_key, ccm_bin_key_indices, average=False, not_ccm=False)</code>","text":"<p>Reduce detector data by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> <code>not_ccm</code> <code>bool</code> <p>Whether to indicate that CCM is not being used (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm(self, run, detector_key, ccm_bin_key_indices, average = False, not_ccm=False):\n    \"\"\"\n    Reduce detector data by CCM bins.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    not_ccm : bool, optional\n        Whether to indicate that CCM is not being used (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    if not_ccm:\n        reduced_array = np.zeros(np.max(ccm_indices)+1 )\n    else:\n        reduced_array = np.zeros(np.shape(run.ccm_bins)[0]) \n    np.add.at(reduced_array, ccm_indices, detector)\n    setattr(run, detector_key+'_energy_binned', reduced_array)\n\n    run.update_status('Detector %s binned in energy into key: %s'%(detector_key,detector_key+'_energy_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_ccm_temporal","title":"<code>reduce_detector_ccm_temporal(run, detector_key, timing_bin_key_indices, ccm_bin_key_indices, average=True)</code>","text":"<p>Reduce detector data temporally and by CCM bins.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>ccm_bin_key_indices</code> <code>str</code> <p>The key corresponding to the CCM bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is True).</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_ccm_temporal(self, run, detector_key, timing_bin_key_indices,ccm_bin_key_indices,average=True):\n    \"\"\"\n    Reduce detector data temporally and by CCM bins.\n\n    Parameters\n    ----------\n    run : object\n        The spectroscopy run instance.\n    detector_key : str\n        The key corresponding to the detector data.\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n    ccm_bin_key_indices : str\n        The key corresponding to the CCM bin indices.\n    average : bool, optional\n        Whether to average the reduced data (default is True).\n    \"\"\"\n    detector = getattr(run, detector_key)\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    ccm_indices = getattr(run, ccm_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros((np.shape(run.time_bins)[0]+1, np.shape(run.ccm_bins)[0]))\n    unique_indices =np.column_stack((timing_indices, ccm_indices))\n    np.add.at(reduced_array, (unique_indices[:, 0], unique_indices[:, 1]), detector)\n    reduced_array = reduced_array[:-1,:]\n    setattr(run, detector_key+'_time_energy_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_energy_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.reduce_detector_temporal","title":"<code>reduce_detector_temporal(run, detector_key, timing_bin_key_indices, average=False)</code>","text":"<p>Reduce detector data temporally. Specifically the 1d detector output for XAS data.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>timing_bin_key_indices</code> <code>str</code> <p>The key corresponding to the timing bin indices.</p> required <code>average</code> <code>bool</code> <p>Whether to average the reduced data (default is False).</p> <code>False</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_detector_temporal(self, run, detector_key, timing_bin_key_indices, average=False):\n    \"\"\"\n    Reduce detector data temporally. Specifically the 1d detector output for XAS data.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    timing_bin_key_indices : str\n        The key corresponding to the timing bin indices.\n\n    average : bool, optional\n        Whether to average the reduced data (default is False).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    time_bins=run.time_bins\n    timing_indices = getattr(run, timing_bin_key_indices)#digitized indices from detector\n    reduced_array = np.zeros(np.shape(time_bins)[0]+1)\n    np.add.at(reduced_array, timing_indices, detector)\n    setattr(run, detector_key+'_time_binned', reduced_array)\n    run.update_status('Detector %s binned in time into key: %s'%(detector_key,detector_key+'_time_binned') )\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XASAnalysis.trim_ccm","title":"<code>trim_ccm(run, threshold=120)</code>","text":"<p>Trim CCM values to remove bins with fewer shots than a specified threshold.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>threshold</code> <code>int</code> <p>The minimum number of shots required to keep a CCM value (default is 120).</p> <code>120</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def trim_ccm(self,run,threshold=120):\n    \"\"\"\n    Trim CCM values to remove bins with fewer shots than a specified threshold.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    threshold : int, optional\n        The minimum number of shots required to keep a CCM value (default is 120).\n\n    \"\"\"\n\n    ccm_bins=getattr(run,'ccm_bins',elist_center)\n    ccm_energies=getattr(run,'ccm_energies',elist)\n    counts = np.bincount(bins)\n    trimmed_ccm=ccm_energies[counts[:-1]&gt;120]\n    self.make_ccm_axis(run,ccm_energies)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis","title":"<code>XESAnalysis</code>","text":"<p>               Bases: <code>SpectroscopyAnalysis</code></p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class XESAnalysis(SpectroscopyAnalysis):\n    def __init__(self,xes_line='kbeta'):\n        self.xes_line=xes_line\n        pass\n    def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n        \"\"\"\n        Normalize XES data by summing the signal over a specified pixel range.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data.\n\n        pixel_range : list of int, optional\n            The pixel range to sum over for normalization (default is [300, 550]).\n\n        \"\"\"\n        detector = getattr(run, detector_key)\n        row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n        normed_main = np.divide(detector, row_sum[:,np.newaxis])\n        setattr(run, detector_key+'_normalized', normed_main)\n    def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n        \"\"\"\n        Determination of energy axis by pixels and crystal configuration\n\n        Parameters\n        ----------\n\n        A : float\n            The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n        R : float\n            The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n        pixel_array : array-like\n            Array of pixels to determine the energy of.\n\n        d : float\n            Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n        \"\"\"\n        pix = mm_per_pixel\n        gl = np.arange(energy_axis_length, dtype=np.float64)\n        gl *= pix\n        ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n        factor = 1.2398e4\n        xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n        setattr(run,self.xes_line+'_energy',xaxis[::-1])\n        run.update_status('XES energy axis generated for %s'%(self.xes_line))\n\n    def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n        \"\"\"\n        Reduce detector data by binning according to an arbitrary scan variable.\n\n        This method bins the detector data based on a specified scan variable and its corresponding bins. \n        The result is stored in the `run` object under a new attribute.\n\n        Parameters\n        ----------\n\n        run : object\n            The spectroscopy run instance.\n\n        detector_key : str\n            The key corresponding to the detector data within the run object.\n\n        scanvar_key : str\n            The key corresponding to the scan variable indices.\n\n        scanvar_bins_key : str\n            The key corresponding to the scan variable bins.\n\n        Returns\n        -------\n\n        None\n            The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n        \"\"\"\n\n        detector = getattr(run, detector_key)\n\n        scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n        scanvar_bins=getattr(run, scanvar_bins_key)\n\n        n_bins = len(scanvar_bins)  # Number of bins\n\n        # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n        reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n        # Iterate over the images and accumulate them into reduced_array based on timing_indices\n        for i in range(detector.shape[0]):\n            np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n        # Store the reduced_array in the object, replace 'key_name' with the actual key\n        setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n        # Update status\n        run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.make_energy_axis","title":"<code>make_energy_axis(run, energy_axis_length, A, R, mm_per_pixel=0.05, d=0.895)</code>","text":"<p>Determination of energy axis by pixels and crystal configuration</p> <p>Parameters:</p> Name Type Description Default <code>A</code> <code>float</code> <p>The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.</p> required <code>R</code> <code>float</code> <p>The vH crystal radii (mm) and should not float. This will affect the spectral stretch.</p> required <code>pixel_array</code> <code>array - like</code> <p>Array of pixels to determine the energy of.</p> required <code>d</code> <code>float</code> <p>Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator</p> <code>0.895</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def make_energy_axis(self, run,energy_axis_length, A, R,  mm_per_pixel=0.05, d=0.895):\n    \"\"\"\n    Determination of energy axis by pixels and crystal configuration\n\n    Parameters\n    ----------\n\n    A : float\n        The detector to vH distance (mm) and can roughly float. This will affect the spectral offset.\n\n    R : float\n        The vH crystal radii (mm) and should not float. This will affect the spectral stretch.\n\n    pixel_array : array-like\n        Array of pixels to determine the energy of.\n\n    d : float\n        Crystal d-spacing. To calculate, visit: spectra.tools/bin/controller.pl?body=Bragg_Angle_Calculator\n\n    \"\"\"\n    pix = mm_per_pixel\n    gl = np.arange(energy_axis_length, dtype=np.float64)\n    gl *= pix\n    ll = gl / 2 - (np.amax(gl) - np.amin(gl)) / 4\n    factor = 1.2398e4\n    xaxis = factor / (2.0 * d * np.sin(np.arctan(R / (ll + A))))\n\n    setattr(run,self.xes_line+'_energy',xaxis[::-1])\n    run.update_status('XES energy axis generated for %s'%(self.xes_line))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.normalize_xes","title":"<code>normalize_xes(run, detector_key, pixel_range=[300, 550])</code>","text":"<p>Normalize XES data by summing the signal over a specified pixel range.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data.</p> required <code>pixel_range</code> <code>list of int</code> <p>The pixel range to sum over for normalization (default is [300, 550]).</p> <code>[300, 550]</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def normalize_xes(self,run,detector_key,pixel_range=[300,550]):\n    \"\"\"\n    Normalize XES data by summing the signal over a specified pixel range.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data.\n\n    pixel_range : list of int, optional\n        The pixel range to sum over for normalization (default is [300, 550]).\n\n    \"\"\"\n    detector = getattr(run, detector_key)\n    row_sum = np.sum(detector[:, pixel_range[0]:pixel_range[1]], axis=1)\n    normed_main = np.divide(detector, row_sum[:,np.newaxis])\n    setattr(run, detector_key+'_normalized', normed_main)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESAnalysis.reduce_det_scanvar","title":"<code>reduce_det_scanvar(run, detector_key, scanvar_key, scanvar_bins_key)</code>","text":"<p>Reduce detector data by binning according to an arbitrary scan variable.</p> <p>This method bins the detector data based on a specified scan variable and its corresponding bins.  The result is stored in the <code>run</code> object under a new attribute.</p> <p>Parameters:</p> Name Type Description Default <code>run</code> <code>object</code> <p>The spectroscopy run instance.</p> required <code>detector_key</code> <code>str</code> <p>The key corresponding to the detector data within the run object.</p> required <code>scanvar_key</code> <code>str</code> <p>The key corresponding to the scan variable indices.</p> required <code>scanvar_bins_key</code> <code>str</code> <p>The key corresponding to the scan variable bins.</p> required <p>Returns:</p> Type Description <code>None</code> <p>The reduced data is stored in the <code>run</code> object with the key formatted as <code>{detector_key}_scanvar_reduced</code>.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def reduce_det_scanvar(self, run, detector_key, scanvar_key, scanvar_bins_key):\n    \"\"\"\n    Reduce detector data by binning according to an arbitrary scan variable.\n\n    This method bins the detector data based on a specified scan variable and its corresponding bins. \n    The result is stored in the `run` object under a new attribute.\n\n    Parameters\n    ----------\n\n    run : object\n        The spectroscopy run instance.\n\n    detector_key : str\n        The key corresponding to the detector data within the run object.\n\n    scanvar_key : str\n        The key corresponding to the scan variable indices.\n\n    scanvar_bins_key : str\n        The key corresponding to the scan variable bins.\n\n    Returns\n    -------\n\n    None\n        The reduced data is stored in the `run` object with the key formatted as `{detector_key}_scanvar_reduced`.\n\n    \"\"\"\n\n    detector = getattr(run, detector_key)\n\n    scanvar_indices = getattr(run, scanvar_key)  # Shape: (4509,)\n    scanvar_bins=getattr(run, scanvar_bins_key)\n\n    n_bins = len(scanvar_bins)  # Number of bins\n\n    # Initialize reduced_array with the correct shape (number of bins, 699, 50)\n    reduced_array = np.zeros((n_bins, detector.shape[1], detector.shape[2]))\n\n    # Iterate over the images and accumulate them into reduced_array based on timing_indices\n    for i in range(detector.shape[0]):\n        np.add.at(reduced_array, (scanvar_indices[i],), detector[i])\n\n    # Store the reduced_array in the object, replace 'key_name' with the actual key\n    setattr(run,  f\"{detector_key}_scanvar_reduced\", reduced_array)\n\n    # Update status\n    run.update_status(f'Detector binned in time into key: {detector_key}_scanvar_reduced')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESVisualization","title":"<code>XESVisualization</code>","text":"<p>               Bases: <code>SpectroscopyVisualization</code></p> Source code in <code>XSpect/XSpect_Visualization.py</code> <pre><code>class XESVisualization(SpectroscopyVisualization):\n    def __init__(self):\n        self.vmin=-0.1\n        self.vmax=0.1\n        pass\n    def plot_1d_XES(self, run, detector_key, target_key, low=-np.inf,high=np.inf,axis=0):\n        target=getattr(run,target_key)\n        intensities=getattr(run,detector_key)\n        if hasattr(run,run.xes_line+'_energy'):        \n            idxlow=np.argmin(np.abs(target-low))\n            idxhigh=np.argmin(np.abs(target-high))\n            cut=np.nanmean(intensities[idxlow:idxhigh,:],axis=axis)\n            plt.plot(getattr(run,run.xes_line+'_energy'),cut)\n            run.current_cut=cut\n        else:\n            raise ValueError('There is no energy axis in this object')\n\n    def combine_spectra(self,xes_analysis,xes_key,xes_laser_key):\n        xes=getattr(xes_analysis.analyzed_runs[0],xes_key)\n        xes_laser=getattr(xes_analysis.analyzed_runs[0],xes_laser_key)\n        summed_laser_off=np.zeros_like(xes)\n        summed_laser_on=np.zeros_like(xes_laser)\n        for run in xes_analysis.analyzed_runs:\n            summed_laser_on+=getattr(run,xes_laser_key)\n            summed_laser_off+=getattr(run,xes_key)\n        self.summed_laser_on=summed_laser_on\n        self.summed_laser_off=summed_laser_off\n        analysis=XESAnalysis()\n        analysis.normalize_xes(self,'summed_laser_on')\n        analysis.normalize_xes(self,'summed_laser_off')\n        xes_analysis.summed_laser_on_normalized=self.summed_laser_on_normalized\n        xes_analysis.summed_laser_off_normalized=self.summed_laser_off_normalized\n\n    def combine_static_spectra(self,xes_analysis,xes_key):\n        xes=getattr(xes_analysis.analyzed_runs[0],xes_key)     \n        summed_laser_off=np.zeros_like(xes)       \n        for run in xes_analysis.analyzed_runs: \n            current_xes=getattr(run,xes_key)\n            if not np.isnan(current_xes).any():\n                summed_laser_off+=current_xes\n        self.summed_xes=summed_laser_off\n\n\n\n    def plot_2d_difference_spectrum(self,xes_analysis):\n        laser_on_spectrum=xes_analysis.summed_laser_on_normalized\n        laser_off_spectrum=xes_analysis.summed_laser_off_normalized\n        difference_spectrum=laser_on_spectrum-laser_off_spectrum\n        try:\n            energy=xes_analysis.analyzed_runs[0].kbeta_energy\n        except:\n            energy=np.linspace(0,np.shape(laser_on_spectrum),1)\n        #vmin, vmax = np.percentile(difference_spectrum, [0,99])\n        plt.figure(dpi=100)\n        plt.imshow(difference_spectrum.T, cmap='RdBu', vmin=self.vmin, vmax=self.vmax, origin='lower',aspect='auto',extent=[xes_analysis.mintime,xes_analysis.maxtime,energy[0],energy[-1]])\n        plt.colorbar()\n        plt.xlabel('Time (ps)')\n        plt.ylabel('Energy (keV)')\n        setattr(xes_analysis,'difference_spectrum',difference_spectrum)\n\n    def normalize_spectrum(self, low, high):\n        \"\"\"\n        Normalize the spectrum (x, y) to unity based on the specified range [low, high].\n\n        Parameters:\n        x (np.ndarray): Energy values.\n        y (np.ndarray): Intensity values.\n        low (float): Lower bound of the energy range for normalization.\n        high (float): Upper bound of the energy range for normalization.\n\n        Returns:\n        np.ndarray: Normalized intensity values.\n        \"\"\"\n        y=self.background_subtracted\n        x=self.energy\n        mask = (x &gt;= low) &amp; (x &lt;= high)\n        area = np.trapz(y[mask], x[mask])\n        if area == 0:\n            raise ValueError(\"The area for normalization is zero, normalization cannot be performed.\")\n        normalized_y = y / area\n        setattr(self,'normalized',normalized_y)\n\n    def normalize_peak(self, low, high):\n        \"\"\"\n        Normalize the spectrum (x, y) to unity based on the specified range [low, high].\n\n        Parameters:\n        x (np.ndarray): Energy values.\n        y (np.ndarray): Intensity values.\n        low (float): Lower bound of the energy range for normalization.\n        high (float): Upper bound of the energy range for normalization.\n\n        Returns:\n        np.ndarray: Normalized intensity values.\n        \"\"\"\n        y=self.background_subtracted\n        x=self.energy\n        mask = (x &gt;= low) &amp; (x &lt;= high)\n        y_peak = np.max(y[mask])\n        if y_peak == 0:\n            raise ValueError(\"The peak for normalization is zero, normalization cannot be performed.\")\n        normalized_peak = y / y_peak\n        setattr(self,'normalized_peak',normalized_peak)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESVisualization.normalize_peak","title":"<code>normalize_peak(low, high)</code>","text":"<p>Normalize the spectrum (x, y) to unity based on the specified range [low, high].</p> <p>Parameters: x (np.ndarray): Energy values. y (np.ndarray): Intensity values. low (float): Lower bound of the energy range for normalization. high (float): Upper bound of the energy range for normalization.</p> <p>Returns: np.ndarray: Normalized intensity values.</p> Source code in <code>XSpect/XSpect_Visualization.py</code> <pre><code>def normalize_peak(self, low, high):\n    \"\"\"\n    Normalize the spectrum (x, y) to unity based on the specified range [low, high].\n\n    Parameters:\n    x (np.ndarray): Energy values.\n    y (np.ndarray): Intensity values.\n    low (float): Lower bound of the energy range for normalization.\n    high (float): Upper bound of the energy range for normalization.\n\n    Returns:\n    np.ndarray: Normalized intensity values.\n    \"\"\"\n    y=self.background_subtracted\n    x=self.energy\n    mask = (x &gt;= low) &amp; (x &lt;= high)\n    y_peak = np.max(y[mask])\n    if y_peak == 0:\n        raise ValueError(\"The peak for normalization is zero, normalization cannot be performed.\")\n    normalized_peak = y / y_peak\n    setattr(self,'normalized_peak',normalized_peak)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.XESVisualization.normalize_spectrum","title":"<code>normalize_spectrum(low, high)</code>","text":"<p>Normalize the spectrum (x, y) to unity based on the specified range [low, high].</p> <p>Parameters: x (np.ndarray): Energy values. y (np.ndarray): Intensity values. low (float): Lower bound of the energy range for normalization. high (float): Upper bound of the energy range for normalization.</p> <p>Returns: np.ndarray: Normalized intensity values.</p> Source code in <code>XSpect/XSpect_Visualization.py</code> <pre><code>def normalize_spectrum(self, low, high):\n    \"\"\"\n    Normalize the spectrum (x, y) to unity based on the specified range [low, high].\n\n    Parameters:\n    x (np.ndarray): Energy values.\n    y (np.ndarray): Intensity values.\n    low (float): Lower bound of the energy range for normalization.\n    high (float): Upper bound of the energy range for normalization.\n\n    Returns:\n    np.ndarray: Normalized intensity values.\n    \"\"\"\n    y=self.background_subtracted\n    x=self.energy\n    mask = (x &gt;= low) &amp; (x &lt;= high)\n    area = np.trapz(y[mask], x[mask])\n    if area == 0:\n        raise ValueError(\"The area for normalization is zero, normalization cannot be performed.\")\n    normalized_y = y / area\n    setattr(self,'normalized',normalized_y)\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment","title":"<code>experiment</code>","text":"Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class experiment:\n    def __init__(self, lcls_run, hutch, experiment_id):\n        \"\"\"\n        Initializes an experiment instance.\n\n        Parameters\n        ----------\n\n        lcls_run : str\n            LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n        hutch : str\n            Hutch name. Example: xcs\n\n        experiment_id : str\n            Experiment identifier. Example: xcsl1004021\n\n        \"\"\"\n        self.lcls_run = lcls_run\n        self.hutch = hutch\n        self.experiment_id = experiment_id\n        self.get_experiment_directory()\n    def get_experiment_directory(self):\n        \"\"\"\n        Determines and returns the directory of the experiment based on the hutch and experiment ID. \n        It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n        Returns\n        -------\n\n        str\n            The directory of the experiment.\n\n        Raises\n        ------\n\n        Exception\n            If the directory cannot be found.\n\n        \"\"\"\n        experiment_directories = [\n        '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n        '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n        '/reg/d/psdm/%s/%s/hdf5/smalldata'\n        ]\n        for directory in experiment_directories:\n            experiment_directory = directory % (self.hutch, self.experiment_id)\n            if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n                self.experiment_directory=experiment_directory\n                return experiment_directory\n        raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.__init__","title":"<code>__init__(lcls_run, hutch, experiment_id)</code>","text":"<p>Initializes an experiment instance.</p> <p>Parameters:</p> Name Type Description Default <code>lcls_run</code> <code>str</code> <p>LCLS run identifier. The LCLS run not the scan/run. Example: 21</p> required <code>hutch</code> <code>str</code> <p>Hutch name. Example: xcs</p> required <code>experiment_id</code> <code>str</code> <p>Experiment identifier. Example: xcsl1004021</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self, lcls_run, hutch, experiment_id):\n    \"\"\"\n    Initializes an experiment instance.\n\n    Parameters\n    ----------\n\n    lcls_run : str\n        LCLS run identifier. The LCLS run not the scan/run. Example: 21\n\n    hutch : str\n        Hutch name. Example: xcs\n\n    experiment_id : str\n        Experiment identifier. Example: xcsl1004021\n\n    \"\"\"\n    self.lcls_run = lcls_run\n    self.hutch = hutch\n    self.experiment_id = experiment_id\n    self.get_experiment_directory()\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.experiment.get_experiment_directory","title":"<code>get_experiment_directory()</code>","text":"<p>Determines and returns the directory of the experiment based on the hutch and experiment ID.  It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.</p> <p>Returns:</p> Type Description <code>str</code> <p>The directory of the experiment.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the directory cannot be found.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_experiment_directory(self):\n    \"\"\"\n    Determines and returns the directory of the experiment based on the hutch and experiment ID. \n    It attempts the various paths LCLS has had over the years with recent S3DF paths being the first attempt.\n\n    Returns\n    -------\n\n    str\n        The directory of the experiment.\n\n    Raises\n    ------\n\n    Exception\n        If the directory cannot be found.\n\n    \"\"\"\n    experiment_directories = [\n    '/sdf/data/lcls/ds/%s/%s/hdf5/smalldata',\n    '/reg/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/cds/data/drpsrcf/%s/%s/scratch/hdf5/smalldata',\n    '/reg/d/psdm/%s/%s/hdf5/smalldata'\n    ]\n    for directory in experiment_directories:\n        experiment_directory = directory % (self.hutch, self.experiment_id)\n        if os.path.exists(experiment_directory) and os.listdir(experiment_directory):\n            self.experiment_directory=experiment_directory\n            return experiment_directory\n    raise Exception(\"Unable to find experiment directory.\")\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_experiment","title":"<code>spectroscopy_experiment</code>","text":"<p>               Bases: <code>experiment</code></p> <p>A class to represent a spectroscopy experiment.  Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_experiment(experiment):\n    \"\"\"\n    A class to represent a spectroscopy experiment. \n    Trying to integrate methods that incorporate meta parameters of the experiment but did not follow through.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n    def add_detector(self, detector_name, detector_dimensions):\n        self.detector_name = detector_name\n        self.detector_dimensions = detector_dimensions\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run","title":"<code>spectroscopy_run</code>","text":"<p>A class to represent a run within a spectroscopy experiment. Not an LCLS run.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>class spectroscopy_run:\n    \"\"\"\n    A class to represent a run within a spectroscopy experiment. Not an LCLS run. \n    \"\"\"\n    def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n        \"\"\"\n        Initializes a spectroscopy run instance.\n\n        Parameters\n        ----------\n\n        spec_experiment : spectroscopy_experiment\n            The parent spectroscopy experiment.\n\n        run : int\n            The run number.\n\n        verbose : bool, optional\n            Flag for verbose output used for printing all of the status updates. \n            These statuses are also available in the object itself. Defaults to False.\n\n        end_index : int, optional\n            Index to stop processing data. Defaults to -1.\n\n        start_index : int, optional\n            Index to start processing data. Defaults to 0.\n            These indices are used for batch analysis. \n\n        \"\"\"\n        self.spec_experiment=spec_experiment\n        self.run_number=run\n        self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n        self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n        self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n        self.verbose=verbose\n        self.end_index=end_index\n        self.start_index=start_index\n\n    def get_scan_val(self):\n        \"\"\"\n        Retrieves the scan variable from the HDF5 file of the run. \n        This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.scan_var=fh['scan/scan_variable']\n\n\n    def update_status(self,update):\n        \"\"\"\n        Updates the status log for the run and appends it to the objects status/datetime attibutes.\n        If verbose then it prints it.\n\n        Parameters\n        ----------\n\n        update : str\n            The status update message.\n\n        \"\"\"\n        self.status.append(update)\n        self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n        if self.verbose:\n            print(update)\n\n    def get_run_shot_properties(self):\n        \"\"\"\n        Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n            xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n            laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n            self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n            self.simultaneous=np.logical_and(self.xray,self.laser)\n\n        self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n        self.update_status('Obtained shot properties')\n    def set_arbitrary_filter(self,key='arbitrary_filter'):\n        self.verbose=False\n        with h5py.File(self.run_file, 'r') as fh:\n            self.arbitrary_filter = fh[key][self.start_index:self.end_index]\n\n    def load_run_keys(self, keys, friendly_names):\n        \"\"\"\n        Loads specified keys from the run file into memory.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load from the hdf5 file\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n        \"\"\"\n        start=time.time()\n        with h5py.File(self.run_file, 'r') as fh:\n            for key, name in zip(keys, friendly_names):\n\n                try:\n                    setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n                except KeyError as e:\n                    self.update_status('Key does not exist: %s' % e.args[0])\n                except MemoryError:\n                    setattr(self, name, fh[key])\n                    self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n        end=time.time()\n        self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n    def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n        \"\"\"\n        Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n        Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n        Parameters\n        ----------\n\n        keys : list\n            List of keys to load.\n\n        friendly_names : list\n            Corresponding list of friendly names for the keys.\n\n        transpose : bool, optional\n            Flag to transpose the loaded data. Defaults to False.\n\n        rois : list of lists, optional\n            List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n            Each ROI should be in the form [start_col, end_col].\n\n        combine : bool, optional\n            Whether to combine ROIs into a single mask. Defaults to True.\n\n        \"\"\"\n        start = time.time()\n        fh = h5py.File(self.run_file, 'r')\n\n        for key, name in zip(keys, friendly_names):\n            try:\n                # Load the data from the file for the given key\n                data = fh[key][self.start_index:self.end_index, :, :]\n\n                # Apply one-dimensional ROIs if specified\n                if rois is not None:\n                    if combine:\n                        # Combine multiple ROIs into a single mask\n                        mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                        for roi in rois:\n                            start_col, end_col = roi\n                            mask[start_col:end_col] = True\n                        # Apply the mask to select the ROI from the third dimension\n                        data = data[:, :, mask]\n                    else:\n                        # Handle each ROI separately, storing the results as different attributes\n                        for idx, roi in enumerate(rois):\n                            start_col, end_col = roi\n                            roi_data = data[:, :, start_col:end_col]\n                            setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n                setattr(self, name, data)\n\n                if transpose:\n                    setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n            except KeyError as e:\n                self.update_status(f'Key does not exist: {e.args[0]}')\n            except MemoryError:\n                setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n                self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n        end = time.time()\n        self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n        self.h5 = fh\n\n\n\n    def load_sum_run_scattering(self,key,low=20,high=80):\n        \"\"\"\n        Sums the scattering data across the specified range.\n\n        Parameters\n        ----------\n\n        key : str\n            The key to sum the scattering data from.\n\n        low : int\n            Low index for summing\n\n        high: int \n            high index for summing\n            These indices should be chosen over the water ring or some scattering of interest.\n\n        \"\"\"\n        with h5py.File(self.run_file, 'r') as fh:\n            setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n\n    def close_h5(self):\n        \"\"\"\n        Closes the HDF5 file handle.\n        Again, avoiding memory issues.\n        \"\"\"\n        self.h5.close()\n        del self.h5\n\n    def purge_all_keys(self,keys_to_keep):\n        \"\"\"\n        Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n        Parameters\n        ----------\n\n        keys_to_keep : list\n            List of keys to retain.\n\n        \"\"\"\n\n        new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n        self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.__init__","title":"<code>__init__(spec_experiment, run, verbose=False, end_index=-1, start_index=0)</code>","text":"<p>Initializes a spectroscopy run instance.</p> <p>Parameters:</p> Name Type Description Default <code>spec_experiment</code> <code>spectroscopy_experiment</code> <p>The parent spectroscopy experiment.</p> required <code>run</code> <code>int</code> <p>The run number.</p> required <code>verbose</code> <code>bool</code> <p>Flag for verbose output used for printing all of the status updates.  These statuses are also available in the object itself. Defaults to False.</p> <code>False</code> <code>end_index</code> <code>int</code> <p>Index to stop processing data. Defaults to -1.</p> <code>-1</code> <code>start_index</code> <code>int</code> <p>Index to start processing data. Defaults to 0. These indices are used for batch analysis.</p> <code>0</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def __init__(self,spec_experiment,run,verbose=False,end_index=-1,start_index=0):\n    \"\"\"\n    Initializes a spectroscopy run instance.\n\n    Parameters\n    ----------\n\n    spec_experiment : spectroscopy_experiment\n        The parent spectroscopy experiment.\n\n    run : int\n        The run number.\n\n    verbose : bool, optional\n        Flag for verbose output used for printing all of the status updates. \n        These statuses are also available in the object itself. Defaults to False.\n\n    end_index : int, optional\n        Index to stop processing data. Defaults to -1.\n\n    start_index : int, optional\n        Index to start processing data. Defaults to 0.\n        These indices are used for batch analysis. \n\n    \"\"\"\n    self.spec_experiment=spec_experiment\n    self.run_number=run\n    self.run_file='%s/%s_Run%04d.h5' % (self.spec_experiment.experiment_directory, self.spec_experiment.experiment_id, self.run_number)\n    self.status=['New analysis of run %d located in: %s' % (self.run_number,self.run_file)]\n    self.status_datetime=[datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")]\n    self.verbose=verbose\n    self.end_index=end_index\n    self.start_index=start_index\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.close_h5","title":"<code>close_h5()</code>","text":"<p>Closes the HDF5 file handle. Again, avoiding memory issues.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def close_h5(self):\n    \"\"\"\n    Closes the HDF5 file handle.\n    Again, avoiding memory issues.\n    \"\"\"\n    self.h5.close()\n    del self.h5\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.get_run_shot_properties","title":"<code>get_run_shot_properties()</code>","text":"<p>Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_run_shot_properties(self):\n    \"\"\"\n    Retrieves shot properties from the run file, including total shots and simultaneous laser and X-ray shots.\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.total_shots = fh['lightStatus/xray'][self.start_index:self.end_index].shape[0]\n        xray_total = np.sum(fh['lightStatus/xray'][self.start_index:self.end_index])\n        laser_total = np.sum(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.xray = np.array(fh['lightStatus/xray'][self.start_index:self.end_index])\n        self.laser = np.array(fh['lightStatus/laser'][self.start_index:self.end_index])\n        self.simultaneous=np.logical_and(self.xray,self.laser)\n\n    self.run_shots={'Total':self.total_shots,'X-ray Total':xray_total,'Laser Total':laser_total}\n    self.update_status('Obtained shot properties')\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.get_scan_val","title":"<code>get_scan_val()</code>","text":"<p>Retrieves the scan variable from the HDF5 file of the run.  This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans</p> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def get_scan_val(self):\n    \"\"\"\n    Retrieves the scan variable from the HDF5 file of the run. \n    This is specifically for runengine scans that tag the variable in the hdf5 file. E.g. useful for processing alignment scans\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        self.scan_var=fh['scan/scan_variable']\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_key_delayed","title":"<code>load_run_key_delayed(keys, friendly_names, transpose=False, rois=None, combine=True)</code>","text":"<p>Loads specified keys from the run file into memory without immediate conversion to numpy arrays.  Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list</code> <p>List of keys to load.</p> required <code>friendly_names</code> <code>list</code> <p>Corresponding list of friendly names for the keys.</p> required <code>transpose</code> <code>bool</code> <p>Flag to transpose the loaded data. Defaults to False.</p> <code>False</code> <code>rois</code> <code>list of lists</code> <p>List of ROIs (regions of interest) as pixel ranges along one dimension (default is None). Each ROI should be in the form [start_col, end_col].</p> <code>None</code> <code>combine</code> <code>bool</code> <p>Whether to combine ROIs into a single mask. Defaults to True.</p> <code>True</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_key_delayed(self, keys, friendly_names, transpose=False, rois=None, combine=True):\n    \"\"\"\n    Loads specified keys from the run file into memory without immediate conversion to numpy arrays. \n    Supports applying multiple ROIs in one dimension that can be combined into a single mask or handled separately.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load.\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys.\n\n    transpose : bool, optional\n        Flag to transpose the loaded data. Defaults to False.\n\n    rois : list of lists, optional\n        List of ROIs (regions of interest) as pixel ranges along one dimension (default is None).\n        Each ROI should be in the form [start_col, end_col].\n\n    combine : bool, optional\n        Whether to combine ROIs into a single mask. Defaults to True.\n\n    \"\"\"\n    start = time.time()\n    fh = h5py.File(self.run_file, 'r')\n\n    for key, name in zip(keys, friendly_names):\n        try:\n            # Load the data from the file for the given key\n            data = fh[key][self.start_index:self.end_index, :, :]\n\n            # Apply one-dimensional ROIs if specified\n            if rois is not None:\n                if combine:\n                    # Combine multiple ROIs into a single mask\n                    mask = np.zeros(data.shape[2], dtype=bool)  # Mask along the third dimension (spatial)\n                    for roi in rois:\n                        start_col, end_col = roi\n                        mask[start_col:end_col] = True\n                    # Apply the mask to select the ROI from the third dimension\n                    data = data[:, :, mask]\n                else:\n                    # Handle each ROI separately, storing the results as different attributes\n                    for idx, roi in enumerate(rois):\n                        start_col, end_col = roi\n                        roi_data = data[:, :, start_col:end_col]\n                        setattr(self, f\"{name}_ROI_{idx+1}\", roi_data)\n\n            setattr(self, name, data)\n\n            if transpose:\n                setattr(self, name, np.transpose(data, axes=(1, 2)))\n\n        except KeyError as e:\n            self.update_status(f'Key does not exist: {e.args[0]}')\n        except MemoryError:\n            setattr(self, name, fh[key][self.start_index:self.end_index, :, :])\n            self.update_status(f'Out of memory error while loading key: {key}. Not converted to np.array.')\n\n    end = time.time()\n    self.update_status(f'HDF5 import of keys completed. Time: {end - start:.02f} seconds')\n    self.h5 = fh\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_run_keys","title":"<code>load_run_keys(keys, friendly_names)</code>","text":"<p>Loads specified keys from the run file into memory.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>list</code> <p>List of keys to load from the hdf5 file</p> required <code>friendly_names</code> <code>list</code> <p>Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_run_keys(self, keys, friendly_names):\n    \"\"\"\n    Loads specified keys from the run file into memory.\n\n    Parameters\n    ----------\n\n    keys : list\n        List of keys to load from the hdf5 file\n\n    friendly_names : list\n        Corresponding list of friendly names for the keys. Some keys are special to the subsequent analyis e.g. epix and ipm. \n\n    \"\"\"\n    start=time.time()\n    with h5py.File(self.run_file, 'r') as fh:\n        for key, name in zip(keys, friendly_names):\n\n            try:\n                setattr(self, name, np.array(fh[key][self.start_index:self.end_index]))\n            except KeyError as e:\n                self.update_status('Key does not exist: %s' % e.args[0])\n            except MemoryError:\n                setattr(self, name, fh[key])\n                self.update_status('Out of memory error while loading key: %s. Not converted to np.array.' % key)\n    end=time.time()\n    self.update_status('HDF5 import of keys completed. Time: %.02f seconds' % (end-start))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.load_sum_run_scattering","title":"<code>load_sum_run_scattering(key, low=20, high=80)</code>","text":"<p>Sums the scattering data across the specified range.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key to sum the scattering data from.</p> required <code>low</code> <code>int</code> <p>Low index for summing</p> <code>20</code> <code>high</code> <p>high index for summing These indices should be chosen over the water ring or some scattering of interest.</p> <code>80</code> Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def load_sum_run_scattering(self,key,low=20,high=80):\n    \"\"\"\n    Sums the scattering data across the specified range.\n\n    Parameters\n    ----------\n\n    key : str\n        The key to sum the scattering data from.\n\n    low : int\n        Low index for summing\n\n    high: int \n        high index for summing\n        These indices should be chosen over the water ring or some scattering of interest.\n\n    \"\"\"\n    with h5py.File(self.run_file, 'r') as fh:\n        setattr(self, 'scattering', np.nansum(np.nansum(fh[key][:,:,low:high],axis=1),axis=1))\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.purge_all_keys","title":"<code>purge_all_keys(keys_to_keep)</code>","text":"<p>Purges all keys from the object except those specified. Again avoid OOM in the analyis object.</p> <p>Parameters:</p> Name Type Description Default <code>keys_to_keep</code> <code>list</code> <p>List of keys to retain.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def purge_all_keys(self,keys_to_keep):\n    \"\"\"\n    Purges all keys from the object except those specified. Again avoid OOM in the analyis object.\n\n    Parameters\n    ----------\n\n    keys_to_keep : list\n        List of keys to retain.\n\n    \"\"\"\n\n    new_dict = {attr: value for attr, value in self.__dict__.items() if attr in keys_to_keep}\n    self.__dict__ = new_dict\n</code></pre>"},{"location":"XSpect_Visualization.html#XSpect.XSpect_Visualization.spectroscopy_run.update_status","title":"<code>update_status(update)</code>","text":"<p>Updates the status log for the run and appends it to the objects status/datetime attibutes. If verbose then it prints it.</p> <p>Parameters:</p> Name Type Description Default <code>update</code> <code>str</code> <p>The status update message.</p> required Source code in <code>XSpect/XSpect_Analysis.py</code> <pre><code>def update_status(self,update):\n    \"\"\"\n    Updates the status log for the run and appends it to the objects status/datetime attibutes.\n    If verbose then it prints it.\n\n    Parameters\n    ----------\n\n    update : str\n        The status update message.\n\n    \"\"\"\n    self.status.append(update)\n    self.status_datetime.append(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n    if self.verbose:\n        print(update)\n</code></pre>"}]}